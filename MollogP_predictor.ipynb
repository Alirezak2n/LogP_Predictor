{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T15:15:22.578885400Z",
     "start_time": "2025-04-25T15:15:20.647562200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chemical_features': (0, 1), 'diamino_chemical_features': (1, 2), 'diamino_atoms': (2, 8), 'atoms': (8, 14), 'sequence_metadata': (14, 21), 'one_hot': (21, 41)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Pycharm_envs\\retention_prediction\\lib\\site-packages\\psims\\mzmlb\\writer.py:33: UserWarning: hdf5plugin is missing! Only the slower GZIP compression scheme will be available! Please install hdf5plugin to be able to use Blosc.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'V': array([0.7693063], dtype=float32),\n 'Y': array([1.1566602], dtype=float32),\n 'W': array([2.1846123], dtype=float32),\n 'T': array([-0.9205796], dtype=float32),\n 'S': array([-1.435417], dtype=float32),\n 'P': array([0.4627892], dtype=float32),\n 'F': array([1.546797], dtype=float32),\n 'M': array([0.89798254], dtype=float32),\n 'K': array([0.07092968], dtype=float32),\n 'L': array([1.2862641], dtype=float32),\n 'I': array([1.2862641], dtype=float32),\n 'H': array([-0.14534178], dtype=float32),\n 'G': array([-0.5884863], dtype=float32),\n 'Q': array([-1.0733744], dtype=float32),\n 'E': array([-0.27918628], dtype=float32),\n 'C': array([-0.19304873], dtype=float32),\n 'D': array([-0.796144], dtype=float32),\n 'N': array([-1.5903322], dtype=float32),\n 'R': array([-1.0763296], dtype=float32),\n 'A': array([-0.07364886], dtype=float32)}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide = \"A\"\n",
    "utilities.aa_chemical_feature()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-25T15:20:52.677127800Z",
     "start_time": "2025-04-25T15:20:52.662177100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import utilities as u\n",
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 peptides: List[str],\n",
    "                 aa_to_idx: Dict[str,int],\n",
    "                 window_size: int = 2):\n",
    "        self.pairs: List[Tuple[int,int]] = []\n",
    "        for pep in peptides:\n",
    "            _, _, seq, _ = u.peptide_parser(pep)\n",
    "            indices = [aa_to_idx[aa] for aa in seq]\n",
    "            for i, center in enumerate(indices):\n",
    "                start = max(0, i - window_size)\n",
    "                end   = min(len(indices), i + window_size + 1)\n",
    "                for j in range(start, end):\n",
    "                    if i == j: continue\n",
    "                    self.pairs.append((center, indices[j]))\n",
    "        # optional: subsample high-freq pairs here\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.pairs[idx][0], dtype=torch.long), \\\n",
    "               torch.tensor(self.pairs[idx][1], dtype=torch.long)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T07:32:26.414967700Z",
     "start_time": "2025-04-28T07:32:26.407487700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_dim: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.out       = nn.Linear(emb_dim, vocab_size, bias=False)\n",
    "    def forward(self, center_idxs):\n",
    "        emb = self.embedding(center_idxs)      # (batch, emb_dim)\n",
    "        logits = self.out(emb)                 # (batch, vocab_size)\n",
    "        return logits\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T07:32:41.869775200Z",
     "start_time": "2025-04-28T07:32:41.854825600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Hyperparameters\n",
    "EMB_DIM      = 16\n",
    "WINDOW_SIZE  = 2\n",
    "BATCH_SIZE   = 512\n",
    "EPOCHS       = 10\n",
    "LEARNING_RATE= 1e-2\n",
    "amino_acids_order= Dict[str, int] = {aa: i for i, aa in enumerate(\"ACDEFGHIKLMNPQRSTVWY\")}\n",
    "# Prepare dataset & loader\n",
    "dataset = SkipGramDataset(peptides=your_peptide_list,\n",
    "                          aa_to_idx=amino_acids_order,\n",
    "                          window_size=WINDOW_SIZE)\n",
    "loader  = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Model + optimizer + loss\n",
    "model = SkipGramModel(vocab_size=len(config.amino_acids_order),\n",
    "                      emb_dim=EMB_DIM)\n",
    "opt   = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for center, context in loader:\n",
    "        opt.zero_grad()\n",
    "        logits = model(center)           # (B, V)\n",
    "        loss   = loss_fn(logits, context)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    avg = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} — avg loss: {avg:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "mods= u.mod_chemical_features()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T07:38:26.178926800Z",
     "start_time": "2025-04-28T07:38:26.157997100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "aas= u.aa_chemical_feature()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T07:38:26.826167300Z",
     "start_time": "2025-04-28T07:38:26.796265100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def build_plogp_map(base_plogp, mod_plogp):\n",
    "    # 1. Base residues → scalar\n",
    "    base_map = { aa: float(val[0]) for aa, val in base_plogp.items() }\n",
    "\n",
    "    # 2. Modified residues → scalar, with key \"X[ModName]\"\n",
    "    mod_map  = {}\n",
    "    for mod_name, aa_dict in mod_plogp.items():\n",
    "        for aa, props in aa_dict.items():\n",
    "            key = f\"{aa}[{mod_name}]\"\n",
    "            mod_map[key] = float(props['MolLogP_rdkit'])\n",
    "\n",
    "    # 3. Combine (mod_map overrides base_map if keys collide)\n",
    "    return { **base_map, **mod_map }\n",
    "\n",
    "# Usage:\n",
    "plogp_map = build_plogp_map(aas, mods)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T07:38:33.797977300Z",
     "start_time": "2025-04-28T07:38:33.776050400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'V': 0.7693063020706177,\n 'Y': 1.1566601991653442,\n 'W': 2.184612274169922,\n 'T': -0.9205796122550964,\n 'S': -1.4354170560836792,\n 'P': 0.4627892076969147,\n 'F': 1.5467970371246338,\n 'M': 0.8979825377464294,\n 'K': 0.07092968374490738,\n 'L': 1.2862640619277954,\n 'I': 1.2862640619277954,\n 'H': -0.14534178376197815,\n 'G': -0.5884863138198853,\n 'Q': -1.0733743906021118,\n 'E': -0.27918627858161926,\n 'C': -0.19304873049259186,\n 'D': -0.7961440086364746,\n 'N': -1.5903321504592896,\n 'R': -1.0763295888900757,\n 'A': -0.0736488550901413,\n 'K[Propionyl]': 0.8229766389241188,\n 'M[Oxidation]': -0.4066698235364236,\n 'P[Oxidation]': -0.9010992826850708,\n 'C[Carbamidomethyl]': -1.135658420367488,\n 'K[Carbamidomethyl]': -1.100275770784884,\n 'C[Methyl]': 0.3810248173586569,\n 'E[Methyl]': -0.1620392200552131,\n 'N[Methyl]': -1.2448543127122975,\n 'K[Methyl]': 0.4164074669412592,\n 'R[Methyl]': -0.7308517548994186,\n 'N[Dimethyl]': -0.7913733131929548,\n 'K[Dimethyl]': 0.869888466460602,\n 'R[Dimethyl]': -0.2773707553800758,\n 'R[Dimethyl_symmetric]': -0.6632271628319939,\n 'K[Crotonyl]': 1.0430911743424789,\n 'K[Succinyl]': 0.1004814871475405,\n 'S[Acetyl]': -0.6789969579643165,\n 'K[Acetyl]': 0.3060189010150147,\n 'C[Acetyl]': 0.2706362514324115,\n 'T[Acetyl]': -0.1641595286444324,\n 'R[Trimethyl]': -0.2097461633126512,\n 'K[Trimethyl]': 1.0615113552113238,\n 'S[Phospho]': -1.2803694815817273,\n 'T[Phospho]': -0.7655320522618425,\n 'Y[Phospho]': 0.8464325526923591,\n 'D[Phospho]': -1.3907580475079733,\n 'C[Phospho]': -0.3307362721849976,\n 'R[Phospho]': -1.4426128444430726,\n 'M[Formyl(N-T)]': 0.61611403218838,\n 'K[Formyl]': -0.2109388368940886,\n 'R[Deamidated]': -0.8308640606671706,\n 'F[Deamidated]': 1.591323463942571,\n 'N[Deamidated]': -0.7961440075187002,\n 'Q[Deamidated]': -0.2791862696095958,\n 'K[Malonyl]': -0.4164762507615646,\n 'Y[Nitro]': 1.035007497846078,\n 'K[Biotin]': 1.241472546721341,\n 'K[Butyryl]': 1.3399343768332224,\n 'K[hydroxyisobutyryl]': -0.0239541231822846,\n 'K[Glutaryl]': 0.6174392250566443,\n 'K[GG]': -2.27148122775506,\n 'C[Dioxidation]': -1.13141780318905,\n 'C[Sulfide]': 0.665941284035041,\n 'K[Gly]': -1.100275770784884,\n 'A[Acetyl(N-T)]': 0.161440359087602,\n 'C[Acetyl(N-T)]': 0.0420404816571733,\n 'D[Acetyl(N-T)]': -0.5610547926889771,\n 'E[Acetyl(N-T)]': -0.0440970547798722,\n 'F[Acetyl(N-T)]': 1.7818861983986825,\n 'G[Acetyl(N-T)]': -0.3533970702322825,\n 'H[Acetyl(N-T)]': 0.0897474249146135,\n 'I[Acetyl(N-T)]': 1.5213532804983243,\n 'K[Acetyl(N-T)]': 0.3060189010150147,\n 'L[Acetyl(N-T)]': 1.5213532804983243,\n 'M[Acetyl(N-T)]': 1.1330717700974846,\n 'N[Acetyl(N-T)]': -1.3552428786385426,\n 'P[Acetyl(N-T)]': 0.8058816509235349,\n 'Q[Acetyl(N-T)]': -0.8382851407294383,\n 'R[Acetyl(N-T)]': -1.1190935095142078,\n 'S[Acetyl(N-T)]': -1.2003278323386866,\n 'T[Acetyl(N-T)]': -0.6854904030188023,\n 'V[Acetyl(N-T)]': 1.0043955425892197,\n 'Y[Acetyl(N-T)]': 1.3917494179822758,\n 'W[Acetyl(N-T)]': 2.4197015258933043}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plogp_map"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T07:38:37.710023Z",
     "start_time": "2025-04-28T07:38:37.698062500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.1 Skip gram for aa and mods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "# --- 1. Build the flattened MolLogP map ------------------------------\n",
    "\n",
    "def build_plogp_map(\n",
    "    base_plogp: Dict[str, np.ndarray],\n",
    "    mod_plogp: Dict[str, Dict[str, Dict[str, float]]]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Merge base-residue and modification-residue MolLogP into one dict.\n",
    "    Keys:\n",
    "      - 'A', 'C', … for unmodified residues\n",
    "      - 'K[Propionyl]', 'M[Oxidation]', … for modified residues\n",
    "    \"\"\"\n",
    "    # a) base residues\n",
    "    base_map = { aa: float(vals[0])\n",
    "                 for aa, vals in base_plogp.items() }\n",
    "\n",
    "    # b) modified residues\n",
    "    mod_map: Dict[str,float] = {}\n",
    "    for mod_name, aa_dict in mod_plogp.items():\n",
    "        for aa, props in aa_dict.items():\n",
    "            key = f\"{aa}[{mod_name}]\"\n",
    "            mod_map[key] = float(props['MolLogP_rdkit'])\n",
    "\n",
    "    # c) merge (mods override if same key ever occurs)\n",
    "    return { **base_map, **mod_map }\n",
    "\n",
    "\n",
    "# 2.1 Build the full token ↔ index mapping\n",
    "plogp_map    = build_plogp_map(aas, mods)\n",
    "token_list   = sorted(plogp_map.keys())\n",
    "token_to_idx = { token: idx for idx, token in enumerate(token_list) }\n",
    "\n",
    "# 2.2 Peptide → list of tokens (plain or modified)\n",
    "def tokenize_peptide(peptide: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parses a ProForma string into tokens like ['A','C','M[Oxidation]',…].\n",
    "    \"\"\"\n",
    "    parsed, modifiers, sequence, _ = u.peptide_parser(peptide)\n",
    "    tokens: List[str] = []\n",
    "    for aa, mods in parsed:\n",
    "        if mods:\n",
    "            tokens.append(f\"{aa}[{mods[0].name}]\")\n",
    "        else:\n",
    "            tokens.append(aa)\n",
    "    return tokens\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 peptides: List[str],\n",
    "                 token_to_idx: Dict[str,int],\n",
    "                 window: int = 2):\n",
    "        self.pairs: List[Tuple[int,int]] = []\n",
    "        for pep in peptides:\n",
    "            toks = tokenize_peptide(pep)\n",
    "            idxs = [ token_to_idx[t] for t in toks ]\n",
    "            for i, center in enumerate(idxs):\n",
    "                for j in range(max(0, i-window),\n",
    "                               min(len(idxs), i+window+1)):\n",
    "                    if i==j: continue\n",
    "                    self.pairs.append((center, idxs[j]))\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, i):\n",
    "        c, ctx = self.pairs[i]\n",
    "        return torch.tensor(c, dtype=torch.long), torch.tensor(ctx, dtype=torch.long)\n",
    "\n",
    "\n",
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_dim: int):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.out = nn.Linear(emb_dim, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, centers: torch.LongTensor):\n",
    "        h      = self.emb(centers)     # (B, emb_dim)\n",
    "        logits = self.out(h)           # (B, vocab_size)\n",
    "        return logits\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T08:08:15.936809500Z",
     "start_time": "2025-04-28T08:08:15.908786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 156120 peptides with 0 errors.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../Data_files/proteometools_library.csv\", keep_default_na=False)\n",
    "peptide_list = []\n",
    "errors = []\n",
    "for idx, row in df.iterrows():\n",
    "    seq = row[\"seq\"]\n",
    "    mod = row[\"modifications\"]\n",
    "    try:\n",
    "        proform = u.reform_seq(seq, mod)\n",
    "        peptide_list.append(proform)\n",
    "    except Exception as e:\n",
    "        errors.append((idx, seq, mod, str(e)))\n",
    "        print(f\"Error at index {idx}: {e}\")\n",
    "print(f\"Parsed {len(peptide_list)} peptides with {len(errors)} errors.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T08:07:18.805165500Z",
     "start_time": "2025-04-28T08:07:16.081445900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 — loss: 2.8952\n",
      "Epoch 2/5 — loss: 2.8907\n",
      "Epoch 3/5 — loss: 2.8907\n",
      "Epoch 4/5 — loss: 2.8906\n",
      "Epoch 5/5 — loss: 2.8906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "EMB_DIM     = 16\n",
    "WINDOW      = 2\n",
    "BATCH_SIZE  = 512\n",
    "EPOCHS      = 5\n",
    "LR          = 1e-2\n",
    "\n",
    "# Prepare data & model\n",
    "dataset = SkipGramDataset(\n",
    "    peptides     = peptide_list,\n",
    "    token_to_idx = token_to_idx,\n",
    "    window       = WINDOW\n",
    ")\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model   = SkipGramModel(vocab_size=len(token_list), emb_dim=EMB_DIM)\n",
    "optim   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for centers, contexts in loader:\n",
    "        optim.zero_grad()\n",
    "        logits = model(centers)\n",
    "        loss   = loss_fn(logits, contexts)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} — loss: {total_loss/len(loader):.4f}\")\n",
    "\n",
    "# Extract embedding matrix for downstream use\n",
    "emb_matrix = model.emb.weight.detach().cpu()  # shape (V, EMB_DIM)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T08:12:26.773127100Z",
     "start_time": "2025-04-28T08:08:34.916394700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.2 improved skip gram for AA and mods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class MolLogPRegressor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embedding_weights: torch.Tensor,\n",
    "                 freeze_emb: bool = True):\n",
    "        super().__init__()\n",
    "        # 5.1 Initialize from pre‐trained Skip-Gram\n",
    "        self.emb = nn.Embedding.from_pretrained(\n",
    "            embeddings = embedding_weights,\n",
    "            freeze     = freeze_emb\n",
    "        )\n",
    "        # 5.2 Single‐layer regressor\n",
    "        self.fc  = nn.Linear(embedding_weights.size(1), 1)\n",
    "\n",
    "    def forward(self, token_ids: torch.LongTensor):\n",
    "        e = self.emb(token_ids)   # (B, emb_dim)\n",
    "        return self.fc(e).squeeze(-1)  # (B,)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T08:12:26.789073800Z",
     "start_time": "2025-04-28T08:12:26.775120Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/50 — loss: 4.5693 — lr: 5.0000e-03\n",
      "Epoch  2/50 — loss: 4.2929 — lr: 5.0000e-03\n",
      "Epoch  3/50 — loss: 3.9357 — lr: 5.0000e-03\n",
      "Epoch  4/50 — loss: 3.7166 — lr: 5.0000e-03\n",
      "Epoch  5/50 — loss: 3.5263 — lr: 5.0000e-03\n",
      "Epoch  6/50 — loss: 3.2405 — lr: 5.0000e-03\n",
      "Epoch  7/50 — loss: 3.0537 — lr: 5.0000e-03\n",
      "Epoch  8/50 — loss: 2.9111 — lr: 5.0000e-03\n",
      "Epoch  9/50 — loss: 2.7111 — lr: 5.0000e-03\n",
      "Epoch 10/50 — loss: 2.5632 — lr: 2.5000e-03\n",
      "Epoch 11/50 — loss: 2.4058 — lr: 2.5000e-03\n",
      "Epoch 12/50 — loss: 2.3673 — lr: 2.5000e-03\n",
      "Epoch 13/50 — loss: 2.3192 — lr: 2.5000e-03\n",
      "Epoch 14/50 — loss: 2.2436 — lr: 2.5000e-03\n",
      "Epoch 15/50 — loss: 2.1919 — lr: 2.5000e-03\n",
      "Epoch 16/50 — loss: 2.1538 — lr: 2.5000e-03\n",
      "Epoch 17/50 — loss: 2.0921 — lr: 2.5000e-03\n",
      "Epoch 18/50 — loss: 2.0315 — lr: 2.5000e-03\n",
      "Epoch 19/50 — loss: 2.0240 — lr: 2.5000e-03\n",
      "Epoch 20/50 — loss: 1.9626 — lr: 1.2500e-03\n",
      "Epoch 21/50 — loss: 1.9138 — lr: 1.2500e-03\n",
      "Epoch 22/50 — loss: 1.9107 — lr: 1.2500e-03\n",
      "Epoch 23/50 — loss: 1.8832 — lr: 1.2500e-03\n",
      "Epoch 24/50 — loss: 1.8781 — lr: 1.2500e-03\n",
      "Epoch 25/50 — loss: 1.8336 — lr: 1.2500e-03\n",
      "Epoch 26/50 — loss: 1.8440 — lr: 1.2500e-03\n",
      "Epoch 27/50 — loss: 1.8161 — lr: 1.2500e-03\n",
      "Epoch 28/50 — loss: 1.7975 — lr: 1.2500e-03\n",
      "Epoch 29/50 — loss: 1.7831 — lr: 1.2500e-03\n",
      "Epoch 30/50 — loss: 1.7747 — lr: 6.2500e-04\n",
      "Epoch 31/50 — loss: 1.7720 — lr: 6.2500e-04\n",
      "Epoch 32/50 — loss: 1.7689 — lr: 6.2500e-04\n",
      "Epoch 33/50 — loss: 1.7520 — lr: 6.2500e-04\n",
      "Epoch 34/50 — loss: 1.7368 — lr: 6.2500e-04\n",
      "Epoch 35/50 — loss: 1.7320 — lr: 6.2500e-04\n",
      "Epoch 36/50 — loss: 1.7232 — lr: 6.2500e-04\n",
      "Epoch 37/50 — loss: 1.7133 — lr: 6.2500e-04\n",
      "Epoch 38/50 — loss: 1.7212 — lr: 6.2500e-04\n",
      "Epoch 39/50 — loss: 1.7082 — lr: 6.2500e-04\n",
      "Epoch 40/50 — loss: 1.6977 — lr: 3.1250e-04\n",
      "Epoch 41/50 — loss: 1.6832 — lr: 3.1250e-04\n",
      "Epoch 42/50 — loss: 1.6873 — lr: 3.1250e-04\n",
      "Epoch 43/50 — loss: 1.7134 — lr: 3.1250e-04\n",
      "Epoch 44/50 — loss: 1.6988 — lr: 3.1250e-04\n",
      "Epoch 45/50 — loss: 1.6932 — lr: 3.1250e-04\n",
      "Epoch 46/50 — loss: 1.6720 — lr: 3.1250e-04\n",
      "Epoch 47/50 — loss: 1.6721 — lr: 3.1250e-04\n",
      "Epoch 48/50 — loss: 1.6726 — lr: 3.1250e-04\n",
      "Epoch 49/50 — loss: 1.6670 — lr: 3.1250e-04\n",
      "Epoch 50/50 — loss: 1.6862 — lr: 1.5625e-04\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "import math\n",
    "\n",
    "def compute_subsampling_probs(peptides, tokenize, tau=1e-5):\n",
    "    # 1) count tokens\n",
    "    counts = Counter(tok for pep in peptides for tok in tokenize(pep))\n",
    "    total = sum(counts.values())\n",
    "    freqs = {tok: cnt/total for tok, cnt in counts.items()}\n",
    "    # 2) compute discard probabilities\n",
    "    subsample_p = {\n",
    "        tok: max(0.0, 1.0 - math.sqrt(tau / freq))\n",
    "        for tok, freq in freqs.items()\n",
    "    }\n",
    "    return subsample_p\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NegSamplingSkipGramDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 peptides: List[str],\n",
    "                 token_to_idx: Dict[str,int],\n",
    "                 subsample_p: Dict[str,float],\n",
    "                 window_max: int = 4,\n",
    "                 neg_k: int = 5):\n",
    "        self.token_to_idx = token_to_idx\n",
    "        self.window_max    = window_max\n",
    "        self.neg_k         = neg_k\n",
    "        self.subsample_p   = subsample_p\n",
    "        self.pairs         = []\n",
    "        self.vocab         = list(token_to_idx.keys())\n",
    "        self.vocab_idx     = list(token_to_idx.values())\n",
    "\n",
    "        # Precompute unigram distribution ^0.75 for negative sampling\n",
    "        freq = Counter()\n",
    "        for pep in peptides:\n",
    "            freq.update(tokenize_peptide(pep))\n",
    "        total_count = sum(freq.values())\n",
    "        unigrams = [ (freq[tok]/total_count)**0.75 for tok in self.vocab ]\n",
    "        Z = sum(unigrams)\n",
    "        self.neg_dist = [u/Z for u in unigrams]  # normalized\n",
    "\n",
    "        # Build positive pairs with subsampling & dynamic window\n",
    "        for pep in peptides:\n",
    "            toks = tokenize_peptide(pep)\n",
    "            idxs = [token_to_idx[t] for t in toks\n",
    "                    if random.random() > subsample_p.get(t,0.0)]\n",
    "            L = len(idxs)\n",
    "            for i, center in enumerate(idxs):\n",
    "                w = random.randint(1, self.window_max)\n",
    "                for j in range(max(0, i-w), min(L, i+w+1)):\n",
    "                    if i==j: continue\n",
    "                    context = idxs[j]\n",
    "                    self.pairs.append((center, context))\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        center, context = self.pairs[idx]\n",
    "        # sample negative examples\n",
    "        negs = torch.multinomial(\n",
    "            torch.tensor(self.neg_dist),\n",
    "            self.neg_k,\n",
    "            replacement=True\n",
    "        ).tolist()\n",
    "        return (\n",
    "            torch.tensor(center, dtype=torch.long),\n",
    "            torch.tensor(context, dtype=torch.long),\n",
    "            torch.tensor(negs,    dtype=torch.long)\n",
    "        )\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SkipGramNegSampling(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_dim: int):\n",
    "        super().__init__()\n",
    "        self.in_emb  = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.out_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "    def forward(self, centers, contexts, negatives):\n",
    "        # centers: (B,)\n",
    "        # contexts: (B,)\n",
    "        # negatives: (B, K)\n",
    "        v_c = self.in_emb(centers)       # (B, D)\n",
    "        v_o = self.out_emb(contexts)     # (B, D)\n",
    "        v_n = self.out_emb(negatives)    # (B, K, D)\n",
    "\n",
    "        # positive score: sigmoid(v_c · v_o)\n",
    "        pos_score = torch.sum(v_c * v_o, dim=1)             # (B,)\n",
    "        # negative scores: sigmoid(-v_c · v_n)\n",
    "        neg_score = torch.bmm(v_n, v_c.unsqueeze(2)).squeeze(2)  # (B, K)\n",
    "\n",
    "        return pos_score, neg_score\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Hyperparameters\n",
    "EMB_DIM     = 32\n",
    "WINDOW_MAX  = 4\n",
    "NEG_K       = 10\n",
    "BATCH_SIZE  = 1024\n",
    "EPOCHS      = 50\n",
    "LR          = 5e-3\n",
    "TAU         = 1e-5  # subsampling threshold\n",
    "\n",
    "# 1) compute subsampling\n",
    "sub_p = compute_subsampling_probs(peptide_list,\n",
    "                                  tokenize_peptide,\n",
    "                                  tau=TAU)\n",
    "\n",
    "# 2) prepare dataset & loader\n",
    "ds = NegSamplingSkipGramDataset(\n",
    "    peptides      = peptide_list,\n",
    "    token_to_idx  = token_to_idx,\n",
    "    subsample_p   = sub_p,\n",
    "    window_max    = WINDOW_MAX,\n",
    "    neg_k         = NEG_K\n",
    ")\n",
    "loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 3) instantiate model, loss, optimizer, scheduler\n",
    "model = SkipGramNegSampling(vocab_size=len(token_list), emb_dim=EMB_DIM)\n",
    "opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# binary cross-entropy with logits\n",
    "bce   = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\n",
    "\n",
    "# 4) train\n",
    "model.train()\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    total_loss = 0.0\n",
    "    for centers, contexts, negatives in loader:\n",
    "        opt.zero_grad()\n",
    "        pos_score, neg_score = model(centers, contexts, negatives)\n",
    "        # labels: positive=1, negatives=0\n",
    "        pos_loss = bce(pos_score, torch.ones_like(pos_score))\n",
    "        neg_loss = bce(neg_score, torch.zeros_like(neg_score))\n",
    "        loss     = pos_loss + neg_loss.mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    sched.step()\n",
    "    avg = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} — loss: {avg:.4f} — lr: {sched.get_last_lr()[0]:.4e}\")\n",
    "final_embeddings = model.in_emb.weight.data\n",
    "final_embeddings.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T08:26:30.781391900Z",
     "start_time": "2025-04-28T08:26:11.050354600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.1 mollog p regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 — MSE: 1.2339\n",
      "Epoch  20 — MSE: 1.0857\n",
      "Epoch  30 — MSE: 1.2373\n",
      "Epoch  40 — MSE: 0.9331\n",
      "Epoch  50 — MSE: 1.0549\n",
      "Epoch  60 — MSE: 0.8477\n",
      "Epoch  70 — MSE: 0.7943\n",
      "Epoch  80 — MSE: 0.7176\n",
      "Epoch  90 — MSE: 0.7042\n",
      "Epoch 100 — MSE: 0.6978\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TokenRegDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 plogp_map: Dict[str,float],\n",
    "                 token_to_idx: Dict[str,int]):\n",
    "        self.items = [\n",
    "            (token_to_idx[tok], plogp_map[tok])\n",
    "            for tok in plogp_map\n",
    "        ]\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, i):\n",
    "        tid, val = self.items[i]\n",
    "        return torch.tensor(tid, dtype=torch.long), \\\n",
    "               torch.tensor(val, dtype=torch.float32)\n",
    "\n",
    "# Prepare regression data\n",
    "reg_ds = TokenRegDataset(plogp_map, token_to_idx)\n",
    "reg_loader = DataLoader(reg_ds, batch_size=16, shuffle=True)\n",
    "\n",
    "# Instantiate regressor (freeze or fine‐tune embedding as you prefer)\n",
    "reg_model = MolLogPRegressor(\n",
    "    embedding_weights = emb_matrix,\n",
    "    freeze_emb        = True\n",
    ")\n",
    "reg_optim = torch.optim.Adam(reg_model.parameters(), lr=1e-3)\n",
    "reg_loss  = nn.MSELoss()\n",
    "\n",
    "# Train\n",
    "reg_model.train()\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0.0\n",
    "    for token_ids, labels in reg_loader:\n",
    "        reg_optim.zero_grad()\n",
    "        preds = reg_model(token_ids)\n",
    "        loss  = reg_loss(preds, labels)\n",
    "        loss.backward()\n",
    "        reg_optim.step()\n",
    "        epoch_loss += loss.item()\n",
    "    if (epoch+1)%10==0:\n",
    "        print(f\"Epoch {epoch+1:3d} — MSE: {epoch_loss/len(reg_loader):.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T08:13:19.579672800Z",
     "start_time": "2025-04-28T08:13:19.357392800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3 Tokenize plain sequence no mods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def tokenize_plain(peptide: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse ProForma → raw sequence, ignore any modifications.\n",
    "    \"\"\"\n",
    "    parsed, modifiers, sequence, _ = u.peptide_parser(peptide)\n",
    "    return list(sequence)\n",
    "\n",
    "\n",
    "def compute_subsampling_probs(\n",
    "    peptides: List[str],\n",
    "    tokenize_fn,\n",
    "    tau: float = 1e-5\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    For each AA token t, compute\n",
    "      P_discard(t) = 1 − sqrt(tau / f(t))\n",
    "    where f(t) = freq(t) in corpus.\n",
    "    \"\"\"\n",
    "    counts = Counter(tok for pep in peptides for tok in tokenize_fn(pep))\n",
    "    total  = sum(counts.values())\n",
    "    freqs  = {t: c/total for t,c in counts.items()}\n",
    "    return { t: max(0.0, 1.0 - math.sqrt(tau / freq))\n",
    "             for t, freq in freqs.items() }\n",
    "\n",
    "class AAOnlySkipGramDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 peptides: List[str],\n",
    "                 aa_to_idx: Dict[str,int],\n",
    "                 window: int = 2):\n",
    "        self.pairs = []\n",
    "        for pep in peptides:\n",
    "            idxs = [aa_to_idx[aa] for aa in tokenize_plain(pep)]\n",
    "            for i, center in enumerate(idxs):\n",
    "                for j in range(max(0, i-window), min(len(idxs), i+window+1)):\n",
    "                    if i == j: continue\n",
    "                    self.pairs.append((center, idxs[j]))\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, i):\n",
    "        c, ctx = self.pairs[i]\n",
    "        return torch.tensor(c), torch.tensor(ctx)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T08:50:43.756274700Z",
     "start_time": "2025-04-28T08:50:43.747467600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.3 Skipgram for AA only"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/30 — loss: 5.0213 — lr: 5.0e-03\n",
      "Epoch  2/30 — loss: 4.6903 — lr: 5.0e-03\n",
      "Epoch  3/30 — loss: 4.3420 — lr: 5.0e-03\n",
      "Epoch  4/30 — loss: 4.0513 — lr: 5.0e-03\n",
      "Epoch  5/30 — loss: 3.8236 — lr: 5.0e-03\n",
      "Epoch  6/30 — loss: 3.5741 — lr: 5.0e-03\n",
      "Epoch  7/30 — loss: 3.3567 — lr: 5.0e-03\n",
      "Epoch  8/30 — loss: 3.1588 — lr: 5.0e-03\n",
      "Epoch  9/30 — loss: 2.9319 — lr: 5.0e-03\n",
      "Epoch 10/30 — loss: 2.8318 — lr: 2.5e-03\n",
      "Epoch 11/30 — loss: 2.6765 — lr: 2.5e-03\n",
      "Epoch 12/30 — loss: 2.6141 — lr: 2.5e-03\n",
      "Epoch 13/30 — loss: 2.6134 — lr: 2.5e-03\n",
      "Epoch 14/30 — loss: 2.4737 — lr: 2.5e-03\n",
      "Epoch 15/30 — loss: 2.4883 — lr: 2.5e-03\n",
      "Epoch 16/30 — loss: 2.3366 — lr: 2.5e-03\n",
      "Epoch 17/30 — loss: 2.2961 — lr: 2.5e-03\n",
      "Epoch 18/30 — loss: 2.2592 — lr: 2.5e-03\n",
      "Epoch 19/30 — loss: 2.1687 — lr: 2.5e-03\n",
      "Epoch 20/30 — loss: 2.1521 — lr: 1.3e-03\n",
      "Epoch 21/30 — loss: 2.1252 — lr: 1.3e-03\n",
      "Epoch 22/30 — loss: 2.0951 — lr: 1.3e-03\n",
      "Epoch 23/30 — loss: 2.0784 — lr: 1.3e-03\n",
      "Epoch 24/30 — loss: 2.0395 — lr: 1.3e-03\n",
      "Epoch 25/30 — loss: 1.9628 — lr: 1.3e-03\n",
      "Epoch 26/30 — loss: 1.9976 — lr: 1.3e-03\n",
      "Epoch 27/30 — loss: 1.9827 — lr: 1.3e-03\n",
      "Epoch 28/30 — loss: 1.9874 — lr: 1.3e-03\n",
      "Epoch 29/30 — loss: 1.9211 — lr: 1.3e-03\n",
      "Epoch 30/30 — loss: 1.9170 — lr: 6.3e-04\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "class AASkipGramNegDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 peptides: List[str],\n",
    "                 aa_to_idx: Dict[str,int],\n",
    "                 subsample_p: Dict[str,float],\n",
    "                 window_max: int = 4,\n",
    "                 neg_k: int = 5):\n",
    "        self.aa_to_idx   = aa_to_idx\n",
    "        self.window_max  = window_max\n",
    "        self.neg_k       = neg_k\n",
    "\n",
    "        # Prepare unigram^0.75 distribution for negatives\n",
    "        token_list = list(aa_to_idx.keys())\n",
    "        raw_counts = Counter(tok for pep in peptides for tok in tokenize_plain(pep))\n",
    "        total = sum(raw_counts.values())\n",
    "        # build list of probs in same order as token_list\n",
    "        unigrams = [(raw_counts[t]/total)**0.75 for t in token_list]\n",
    "        Z = sum(unigrams)\n",
    "        self.neg_dist = [u/Z for u in unigrams]\n",
    "\n",
    "        # Build positive (center,context) pairs with subsampling & dynamic windows\n",
    "        self.pairs: List[tuple] = []\n",
    "        for pep in peptides:\n",
    "            toks = [t for t in tokenize_plain(pep)\n",
    "                    if random.random() > subsample_p.get(t, 0.0)]\n",
    "            idxs = [aa_to_idx[t] for t in toks]\n",
    "            L = len(idxs)\n",
    "            for i, c in enumerate(idxs):\n",
    "                w = random.randint(1, self.window_max)\n",
    "                for j in range(max(0, i-w), min(L, i+w+1)):\n",
    "                    if i == j: continue\n",
    "                    self.pairs.append((c, idxs[j]))\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        center, context = self.pairs[idx]\n",
    "        # sample neg_k negatives (with replacement)\n",
    "        negs = torch.multinomial(\n",
    "            torch.tensor(self.neg_dist),\n",
    "            self.neg_k,\n",
    "            replacement=True\n",
    "        )\n",
    "        return (\n",
    "            torch.tensor(center,  dtype=torch.long),\n",
    "            torch.tensor(context, dtype=torch.long),\n",
    "            negs\n",
    "        )\n",
    "\n",
    "class SkipGramNegSampling(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_dim: int):\n",
    "        super().__init__()\n",
    "        self.in_emb  = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.out_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "    def forward(self, centers, contexts, negs):\n",
    "        # centers: (B,), contexts: (B,), negs: (B, K)\n",
    "        v_c = self.in_emb(centers)       # (B, D)\n",
    "        v_o = self.out_emb(contexts)     # (B, D)\n",
    "        v_n = self.out_emb(negs)         # (B, K, D)\n",
    "\n",
    "        # positive scores: v_c·v_o, negative: v_c·v_n\n",
    "        pos = torch.sum(v_c * v_o, dim=1)               # (B,)\n",
    "        neg = torch.bmm(v_n, v_c.unsqueeze(2)).squeeze(2)  # (B, K)\n",
    "        return pos, neg\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "EMB_DIM    = 32\n",
    "WINDOW_MAX = 4\n",
    "NEG_K      = 10\n",
    "BATCH      = 1024\n",
    "EPOCHS     = 30\n",
    "LR         = 5e-3\n",
    "TAU        = 1e-5  # subsampling threshold\n",
    "amino_acids_order = {aa: i for i, aa in enumerate(\"ACDEFGHIKLMNPQRSTVWY\")}\n",
    "# 5.1 Prepare data\n",
    "peptide_list = peptide_list  # list of ProForma strings\n",
    "sub_p        = compute_subsampling_probs(peptide_list, tokenize_plain, tau=TAU)\n",
    "dataset      = AASkipGramNegDataset(\n",
    "    peptides    = peptide_list,\n",
    "    aa_to_idx   = amino_acids_order,\n",
    "    subsample_p = sub_p,\n",
    "    window_max  = WINDOW_MAX,\n",
    "    neg_k       = NEG_K\n",
    ")\n",
    "loader = DataLoader(dataset, batch_size=BATCH, shuffle=True)\n",
    "\n",
    "# 5.2 Model, loss, optimizer\n",
    "model = SkipGramNegSampling(vocab_size=20, emb_dim=EMB_DIM)\n",
    "opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "bce   = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.5)\n",
    "\n",
    "# 5.3 Train\n",
    "model.train()\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    total_loss = 0.0\n",
    "    for centers, contexts, negs in loader:\n",
    "        opt.zero_grad()\n",
    "        pos_score, neg_score = model(centers, contexts, negs)\n",
    "        # positive labels = 1, negatives = 0\n",
    "        pos_loss = bce(pos_score, torch.ones_like(pos_score))\n",
    "        neg_loss = bce(neg_score, torch.zeros_like(neg_score))\n",
    "        loss     = pos_loss + neg_loss.mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    sched.step()\n",
    "    avg = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch:2d}/{EPOCHS} — loss: {avg:.4f} — lr: {sched.get_last_lr()[0]:.1e}\")\n",
    "\n",
    "# After training, your amino‐acid embeddings are:\n",
    "aa_embeddings = model.in_emb.weight.data  # shape (20, EMB_DIM)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T11:52:55.048250900Z",
     "start_time": "2025-04-29T11:52:38.600681500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "data": {
      "text/plain": "{'V': 0.7693063020706177,\n 'Y': 1.1566601991653442,\n 'W': 2.184612274169922,\n 'T': -0.9205796122550964,\n 'S': -1.4354170560836792,\n 'P': 0.4627892076969147,\n 'F': 1.5467970371246338,\n 'M': 0.8979825377464294,\n 'K': 0.07092968374490738,\n 'L': 1.2862640619277954,\n 'I': 1.2862640619277954,\n 'H': -0.14534178376197815,\n 'G': -0.5884863138198853,\n 'Q': -1.0733743906021118,\n 'E': -0.27918627858161926,\n 'C': -0.19304873049259186,\n 'D': -0.7961440086364746,\n 'N': -1.5903321504592896,\n 'R': -1.0763295888900757,\n 'A': -0.0736488550901413,\n 'K[Propionyl]': 0.8229766389241188,\n 'M[Oxidation]': -0.4066698235364236,\n 'P[Oxidation]': -0.9010992826850708,\n 'C[Carbamidomethyl]': -1.135658420367488,\n 'K[Carbamidomethyl]': -1.100275770784884,\n 'C[Methyl]': 0.3810248173586569,\n 'E[Methyl]': -0.1620392200552131,\n 'N[Methyl]': -1.2448543127122975,\n 'K[Methyl]': 0.4164074669412592,\n 'R[Methyl]': -0.7308517548994186,\n 'N[Dimethyl]': -0.7913733131929548,\n 'K[Dimethyl]': 0.869888466460602,\n 'R[Dimethyl]': -0.2773707553800758,\n 'R[Dimethyl_symmetric]': -0.6632271628319939,\n 'K[Crotonyl]': 1.0430911743424789,\n 'K[Succinyl]': 0.1004814871475405,\n 'S[Acetyl]': -0.6789969579643165,\n 'K[Acetyl]': 0.3060189010150147,\n 'C[Acetyl]': 0.2706362514324115,\n 'T[Acetyl]': -0.1641595286444324,\n 'R[Trimethyl]': -0.2097461633126512,\n 'K[Trimethyl]': 1.0615113552113238,\n 'S[Phospho]': -1.2803694815817273,\n 'T[Phospho]': -0.7655320522618425,\n 'Y[Phospho]': 0.8464325526923591,\n 'D[Phospho]': -1.3907580475079733,\n 'C[Phospho]': -0.3307362721849976,\n 'R[Phospho]': -1.4426128444430726,\n 'M[Formyl(N-T)]': 0.61611403218838,\n 'K[Formyl]': -0.2109388368940886,\n 'R[Deamidated]': -0.8308640606671706,\n 'F[Deamidated]': 1.591323463942571,\n 'N[Deamidated]': -0.7961440075187002,\n 'Q[Deamidated]': -0.2791862696095958,\n 'K[Malonyl]': -0.4164762507615646,\n 'Y[Nitro]': 1.035007497846078,\n 'K[Biotin]': 1.241472546721341,\n 'K[Butyryl]': 1.3399343768332224,\n 'K[hydroxyisobutyryl]': -0.0239541231822846,\n 'K[Glutaryl]': 0.6174392250566443,\n 'K[GG]': -2.27148122775506,\n 'C[Dioxidation]': -1.13141780318905,\n 'C[Sulfide]': 0.665941284035041,\n 'K[Gly]': -1.100275770784884,\n 'A[Acetyl(N-T)]': 0.161440359087602,\n 'C[Acetyl(N-T)]': 0.0420404816571733,\n 'D[Acetyl(N-T)]': -0.5610547926889771,\n 'E[Acetyl(N-T)]': -0.0440970547798722,\n 'F[Acetyl(N-T)]': 1.7818861983986825,\n 'G[Acetyl(N-T)]': -0.3533970702322825,\n 'H[Acetyl(N-T)]': 0.0897474249146135,\n 'I[Acetyl(N-T)]': 1.5213532804983243,\n 'K[Acetyl(N-T)]': 0.3060189010150147,\n 'L[Acetyl(N-T)]': 1.5213532804983243,\n 'M[Acetyl(N-T)]': 1.1330717700974846,\n 'N[Acetyl(N-T)]': -1.3552428786385426,\n 'P[Acetyl(N-T)]': 0.8058816509235349,\n 'Q[Acetyl(N-T)]': -0.8382851407294383,\n 'R[Acetyl(N-T)]': -1.1190935095142078,\n 'S[Acetyl(N-T)]': -1.2003278323386866,\n 'T[Acetyl(N-T)]': -0.6854904030188023,\n 'V[Acetyl(N-T)]': 1.0043955425892197,\n 'Y[Acetyl(N-T)]': 1.3917494179822758,\n 'W[Acetyl(N-T)]': 2.4197015258933043}"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plogp_map"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T15:08:40.353178200Z",
     "start_time": "2025-04-28T15:08:40.345204700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "import re\n",
    "def reformat_peptide(peptide: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert ProForma peptide to a format suitable for parsing.\n",
    "    - Remove \"(N-T)\" and \"(C-T)\" suffixes from modifications\n",
    "    \"\"\"\n",
    "    # 1) remove suffixes\n",
    "    peptide = re.sub(\n",
    "        r'([A-Z])\\[(\\w+)\\(N-T\\)\\]',\n",
    "        r'[\\2]-\\1',\n",
    "        peptide\n",
    "    )\n",
    "    # C-terminal on the immediately preceding residue\n",
    "    peptide = re.sub(\n",
    "        r'([A-Z])\\[(\\w+)\\(C-T\\)\\]',\n",
    "        r'\\1-[\\2]',\n",
    "        peptide\n",
    "    )\n",
    "    return peptide\n",
    "def atom_counts(peptide: str) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Count atoms in a peptide sequence.\n",
    "    \"\"\"\n",
    "    if peptide == \"R[Dimethyl_symmetric]\":\n",
    "        peptide = \"R[Dimethyl]\"\n",
    "    peptide = reformat_peptide(peptide)\n",
    "    parsed, modifiers, sequence, _ = u.peptide_parser(peptide)\n",
    "    atoms = u.aa_atomic_composition_array()\n",
    "    encode_seq_mod_atomic = u.encode_sequence_and_modification_atomic(sequence, parsed, atoms, modifiers[\"n_term\"], modifiers[\"c_term\"])\n",
    "\n",
    "    return list(encode_seq_mod_atomic[8:14,1])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T15:09:24.471031400Z",
     "start_time": "2025-04-28T15:09:24.458072100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "plogp_map_atoms = {}\n",
    "for k,v in plogp_map.items():\n",
    "    plogp_map_atoms[k] = (v,atom_counts(k))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T15:29:28.407374100Z",
     "start_time": "2025-04-28T15:29:28.386441600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.2 mollog p predictor for embedding + atom counts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class MolLogPTokenDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item is (aa_idx, atom_counts, mol_logp).\n",
    "      - aa_idx:    index of the base amino acid in 0…19\n",
    "      - atom_counts: 6‐dim atomic composition of the *modification* (or zero for unmodified)\n",
    "      - mol_logp:  target scalar\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 token_data: Dict[str, Tuple[float, List[float]]],\n",
    "                 aa_to_idx: Dict[str,int]):\n",
    "        self.items = []\n",
    "        for token, (mol_logp, atom_counts) in token_data.items():\n",
    "            # strip off any \"[Mod]\" to recover the base AA\n",
    "            aa = token.split('[')[0]\n",
    "            if aa not in aa_to_idx:\n",
    "                raise KeyError(f\"Unknown amino acid '{aa}' in token '{token}'\")\n",
    "            aa_idx = aa_to_idx[aa]\n",
    "            self.items.append((\n",
    "                torch.tensor(aa_idx,       dtype=torch.long),\n",
    "                torch.tensor(atom_counts,  dtype=torch.float32),\n",
    "                torch.tensor(mol_logp,     dtype=torch.float32),\n",
    "            ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.items[idx]\n",
    "\n",
    "# Example usage:\n",
    "dataset = MolLogPTokenDataset(plogp_map_atoms, amino_acids_order)\n",
    "loader  = DataLoader(dataset, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T11:18:16.454417600Z",
     "start_time": "2025-04-28T11:18:16.440197100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MolLogPRegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes:\n",
    "      - aa_idx     → lookup in pretrained AA embedding\n",
    "      - atom_counts → concatenated to that embedding\n",
    "    Outputs:\n",
    "      - a single scalar MolLogP per token.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 aa_embedding: torch.Tensor,\n",
    "                 atom_dim: int = 6,\n",
    "                 hidden_dim: int = 64,\n",
    "                 freeze_aa: bool = True):\n",
    "        super().__init__()\n",
    "        # 1) load pretrained AA embeddings\n",
    "        self.aa_emb = nn.Embedding.from_pretrained(\n",
    "            embeddings = aa_embedding,\n",
    "            freeze     = freeze_aa\n",
    "        )\n",
    "        # 2) simple MLP head\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(aa_embedding.size(1) + atom_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, aa_idx, atom_counts):\n",
    "        e = self.aa_emb(aa_idx)               # (B, D)\n",
    "        x = torch.cat([e, atom_counts], dim=1)  # (B, D+6)\n",
    "        return self.net(x).squeeze(-1)          # (B,)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T11:18:27.169393900Z",
     "start_time": "2025-04-28T11:18:27.133168100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/50 — MSE: 1.5416\n",
      "Epoch  2/50 — MSE: 1.1342\n",
      "Epoch  3/50 — MSE: 0.8933\n",
      "Epoch  4/50 — MSE: 0.8426\n",
      "Epoch  5/50 — MSE: 0.8151\n",
      "Epoch  6/50 — MSE: 0.8059\n",
      "Epoch  7/50 — MSE: 0.7411\n",
      "Epoch  8/50 — MSE: 0.6770\n",
      "Epoch  9/50 — MSE: 0.6391\n",
      "Epoch 10/50 — MSE: 0.5761\n",
      "Epoch 11/50 — MSE: 0.5393\n",
      "Epoch 12/50 — MSE: 0.5193\n",
      "Epoch 13/50 — MSE: 0.4860\n",
      "Epoch 14/50 — MSE: 0.4539\n",
      "Epoch 15/50 — MSE: 0.3978\n",
      "Epoch 16/50 — MSE: 0.4172\n",
      "Epoch 17/50 — MSE: 0.3567\n",
      "Epoch 18/50 — MSE: 0.3352\n",
      "Epoch 19/50 — MSE: 0.3610\n",
      "Epoch 20/50 — MSE: 0.3009\n",
      "Epoch 21/50 — MSE: 0.2898\n",
      "Epoch 22/50 — MSE: 0.2769\n",
      "Epoch 23/50 — MSE: 0.2943\n",
      "Epoch 24/50 — MSE: 0.2943\n",
      "Epoch 25/50 — MSE: 0.2380\n",
      "Epoch 26/50 — MSE: 0.2616\n",
      "Epoch 27/50 — MSE: 0.2533\n",
      "Epoch 28/50 — MSE: 0.2177\n",
      "Epoch 29/50 — MSE: 0.2210\n",
      "Epoch 30/50 — MSE: 0.2329\n",
      "Epoch 31/50 — MSE: 0.2050\n",
      "Epoch 32/50 — MSE: 0.1938\n",
      "Epoch 33/50 — MSE: 0.1964\n",
      "Epoch 34/50 — MSE: 0.1898\n",
      "Epoch 35/50 — MSE: 0.2007\n",
      "Epoch 36/50 — MSE: 0.1907\n",
      "Epoch 37/50 — MSE: 0.2113\n",
      "Epoch 38/50 — MSE: 0.1745\n",
      "Epoch 39/50 — MSE: 0.1711\n",
      "Epoch 40/50 — MSE: 0.1690\n",
      "Epoch 41/50 — MSE: 0.1754\n",
      "Epoch 42/50 — MSE: 0.1572\n",
      "Epoch 43/50 — MSE: 0.1664\n",
      "Epoch 44/50 — MSE: 0.1584\n",
      "Epoch 45/50 — MSE: 0.1583\n",
      "Epoch 46/50 — MSE: 0.1633\n",
      "Epoch 47/50 — MSE: 0.1521\n",
      "Epoch 48/50 — MSE: 0.1818\n",
      "Epoch 49/50 — MSE: 0.1743\n",
      "Epoch 50/50 — MSE: 0.1511\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assume `aa_embedding` is your torch.Tensor from SkipGram: shape (20, D)\n",
    "model = MolLogPRegressor(\n",
    "    aa_embedding = aa_embeddings,\n",
    "    atom_dim     = 6,  # 6\n",
    "    hidden_dim   = 64,\n",
    "    freeze_aa    = True\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn   = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, 51):\n",
    "    total_loss = 0.0\n",
    "    for aa_idx, atom_counts, label in loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(aa_idx, atom_counts)\n",
    "        loss = loss_fn(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch:2d}/50 — MSE: {avg_loss:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T14:57:44.167837800Z",
     "start_time": "2025-04-28T14:57:44.076631100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_peptide_logp(peptide_str,\n",
    "                         model,\n",
    "                         token_data,\n",
    "                         aa_to_idx,\n",
    "                         device='cpu'):\n",
    "    \"\"\"\n",
    "    Returns per-residue and total MolLogP for a peptide.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    tokens = tokenize_peptide(peptide_str)\n",
    "    inputs = []\n",
    "    for tok in tokens:\n",
    "        if tok not in token_data:\n",
    "            raise KeyError(f\"Unknown token: {tok}\")\n",
    "        aa = tok.split('[')[0]\n",
    "        idx = aa_to_idx[aa]\n",
    "        atom_counts = token_data[tok][1]\n",
    "        inputs.append((idx, atom_counts))\n",
    "\n",
    "    # build tensors\n",
    "    aa_idxs      = torch.tensor([i for i,_ in inputs], dtype=torch.long, device=device)\n",
    "    atom_counts  = torch.tensor([a for _,a in inputs], dtype=torch.float32, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mol_preds = model(aa_idxs, atom_counts)  # (L,)\n",
    "\n",
    "    total_logp = mol_preds.sum().item()\n",
    "    return mol_preds.cpu().numpy(), total_logp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T11:58:39.686349300Z",
     "start_time": "2025-04-28T11:58:39.669475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-residue MolLogP: [-1.0204217]\n",
      "Peptide MolLogP total: -1.0204217433929443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "peptide = \"R\"\n",
    "per_res, total = predict_peptide_logp(peptide,\n",
    "                                      model,\n",
    "                                      plogp_map_atoms,\n",
    "                                      amino_acids_order)\n",
    "print(\"Per-residue MolLogP:\", per_res)\n",
    "print(\"Peptide MolLogP total:\", total)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T11:59:21.469376500Z",
     "start_time": "2025-04-28T11:59:21.459113900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP with cv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MSE = 0.2158,  R² = 0.7328\n",
      "Fold 2: MSE = 0.0624,  R² = 0.9396\n",
      "Fold 3: MSE = 0.1030,  R² = 0.8606\n",
      "Fold 4: MSE = 0.1111,  R² = 0.8545\n",
      "Fold 5: MSE = 0.1263,  R² = 0.9134\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Avg MSE over folds: 0.1237 ± 0.0507\n",
      "Avg R²  over folds: 0.8602 ± 0.0713\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. Prepare the feature matrix X and target vector y\n",
    "tokens = list(plogp_map_atoms.keys())\n",
    "X = np.vstack([plogp_map_atoms[tok][1] for tok in tokens])  # shape: (n_tokens, n_features)\n",
    "y = np.array([plogp_map_atoms[tok][0] for tok in tokens], dtype=float)\n",
    "\n",
    "# 2. Convert data to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 3. Define a simple MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # Regression output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()  # Squeeze to make output 1D\n",
    "\n",
    "# 4. Set up 5-fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mse_scores, r2_scores = [], []\n",
    "\n",
    "# 5. Training parameters\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 6. Cross-validation loop\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = MLP(input_dim=X.shape[1]).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        idx = torch.randperm(X_train.size(0))\n",
    "        X_train, y_train = X_train[idx], y_train[idx]\n",
    "\n",
    "        for i in range(0, X_train.size(0), batch_size):\n",
    "            x_batch = X_train[i:i+batch_size].to(device)\n",
    "            y_batch = y_train[i:i+batch_size].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test.to(device)).cpu().numpy()\n",
    "        y_true_test = y_test.numpy()\n",
    "\n",
    "        mse = mean_squared_error(y_true_test, y_pred_test)\n",
    "        r2 = r2_score(y_true_test, y_pred_test)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f\"Fold {fold}: MSE = {mse:.4f},  R² = {r2:.4f}\")\n",
    "\n",
    "# 7. Aggregate results across folds\n",
    "print(f\"\\n=== Final Cross-Validation Results ===\")\n",
    "print(f\"Avg MSE over folds: {np.mean(mse_scores):.4f} ± {np.std(mse_scores):.4f}\")\n",
    "print(f\"Avg R²  over folds: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T11:22:58.971433800Z",
     "start_time": "2025-04-29T11:22:46.486161900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 0.9810\n",
      "Epoch 20/200, Loss: 1.0535\n",
      "Epoch 30/200, Loss: 0.2540\n",
      "Epoch 40/200, Loss: 0.2883\n",
      "Epoch 50/200, Loss: 0.5541\n",
      "Epoch 60/200, Loss: 0.2489\n",
      "Epoch 70/200, Loss: 0.6007\n",
      "Epoch 80/200, Loss: 0.3069\n",
      "Epoch 90/200, Loss: 0.1518\n",
      "Epoch 100/200, Loss: 0.1975\n",
      "Epoch 110/200, Loss: 0.2495\n",
      "Epoch 120/200, Loss: 0.1097\n",
      "Epoch 130/200, Loss: 0.1814\n",
      "Epoch 140/200, Loss: 0.3028\n",
      "Epoch 150/200, Loss: 0.2323\n",
      "Epoch 160/200, Loss: 0.2136\n",
      "Epoch 170/200, Loss: 0.5437\n",
      "Epoch 180/200, Loss: 0.2528\n",
      "Epoch 190/200, Loss: 0.1117\n",
      "Epoch 200/200, Loss: 0.2949\n",
      "\n",
      "Validation MSE: 0.1312\n",
      "Validation R²: 0.8720\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. Prepare the feature matrix X and target vector y\n",
    "tokens = list(plogp_map_atoms.keys())\n",
    "X = np.vstack([plogp_map_atoms[tok][1] for tok in tokens])  # shape: (n_tokens, n_features)\n",
    "y = np.array([plogp_map_atoms[tok][0] for tok in tokens], dtype=float)\n",
    "\n",
    "# 2. Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# 3. Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.float32)\n",
    "\n",
    "# 4. Define a deeper MLP model with more layers and Dropout\n",
    "class DeeperMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeeperMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),  # First hidden layer with 128 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),  # Dropout with 30% probability\n",
    "\n",
    "            nn.Linear(128, 64),  # Second hidden layer with 64 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),  # Dropout again\n",
    "\n",
    "            nn.Linear(64, 32),  # Third hidden layer with 32 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "\n",
    "            nn.Linear(32, 1)  # Output layer for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()  # Squeeze to make output 1D\n",
    "\n",
    "# 5. Training parameters\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 6. Initialize the model, optimizer, and loss function\n",
    "model = DeeperMLP(input_dim=X_train.shape[1]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)  # L2 regularization\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 7. Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle the training data\n",
    "    idx = torch.randperm(X_train.size(0))\n",
    "    X_train, y_train = X_train[idx], y_train[idx]\n",
    "\n",
    "    # Mini-batch training\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        x_batch = X_train[i:i+batch_size].to(device)\n",
    "        y_batch = y_train[i:i+batch_size].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 8. Evaluation on the validation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_valid = model(X_valid.to(device)).cpu().numpy()\n",
    "    mse = mean_squared_error(y_valid.numpy(), y_pred_valid)\n",
    "    r2 = r2_score(y_valid.numpy(), y_pred_valid)\n",
    "\n",
    "# 9. Print results\n",
    "print(f\"\\nValidation MSE: {mse:.4f}\")\n",
    "print(f\"Validation R²: {r2:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T11:29:30.905048300Z",
     "start_time": "2025-04-29T11:29:30.408214100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/2000, Train Loss: 1.1557, Validation Loss: 0.8701\n",
      "Epoch 20/2000, Train Loss: 0.7527, Validation Loss: 0.2669\n",
      "Epoch 30/2000, Train Loss: 0.6110, Validation Loss: 0.1652\n",
      "Epoch 40/2000, Train Loss: 0.4687, Validation Loss: 0.1385\n",
      "Epoch 50/2000, Train Loss: 0.4235, Validation Loss: 0.1345\n",
      "Epoch 60/2000, Train Loss: 0.3352, Validation Loss: 0.1344\n",
      "Epoch 70/2000, Train Loss: 0.3295, Validation Loss: 0.1679\n",
      "Epoch 80/2000, Train Loss: 0.3386, Validation Loss: 0.1304\n",
      "Epoch 90/2000, Train Loss: 0.2587, Validation Loss: 0.1299\n",
      "Epoch 100/2000, Train Loss: 0.2988, Validation Loss: 0.1451\n",
      "Epoch 110/2000, Train Loss: 0.3089, Validation Loss: 0.1249\n",
      "Epoch 120/2000, Train Loss: 0.2472, Validation Loss: 0.1327\n",
      "Epoch 130/2000, Train Loss: 0.2248, Validation Loss: 0.1345\n",
      "Epoch 140/2000, Train Loss: 0.2499, Validation Loss: 0.1604\n",
      "Epoch 150/2000, Train Loss: 0.2279, Validation Loss: 0.1906\n",
      "Epoch 160/2000, Train Loss: 0.2181, Validation Loss: 0.1386\n",
      "Epoch 170/2000, Train Loss: 0.2460, Validation Loss: 0.1543\n",
      "Epoch 180/2000, Train Loss: 0.2003, Validation Loss: 0.1696\n",
      "Epoch 190/2000, Train Loss: 0.2268, Validation Loss: 0.1513\n",
      "Epoch 200/2000, Train Loss: 0.1605, Validation Loss: 0.1549\n",
      "Epoch 210/2000, Train Loss: 0.2046, Validation Loss: 0.1481\n",
      "Epoch 220/2000, Train Loss: 0.1509, Validation Loss: 0.1454\n",
      "Epoch 230/2000, Train Loss: 0.2507, Validation Loss: 0.1527\n",
      "Epoch 240/2000, Train Loss: 0.1441, Validation Loss: 0.1794\n",
      "Epoch 250/2000, Train Loss: 0.1939, Validation Loss: 0.1569\n",
      "Epoch 260/2000, Train Loss: 0.1532, Validation Loss: 0.1858\n",
      "Epoch 270/2000, Train Loss: 0.1755, Validation Loss: 0.1873\n",
      "Epoch 280/2000, Train Loss: 0.2201, Validation Loss: 0.1795\n",
      "Epoch 290/2000, Train Loss: 0.1365, Validation Loss: 0.1762\n",
      "Epoch 300/2000, Train Loss: 0.1472, Validation Loss: 0.1592\n",
      "Epoch 310/2000, Train Loss: 0.1403, Validation Loss: 0.1638\n",
      "Epoch 320/2000, Train Loss: 0.1223, Validation Loss: 0.1922\n",
      "Epoch 330/2000, Train Loss: 0.1640, Validation Loss: 0.1679\n",
      "Epoch 340/2000, Train Loss: 0.1319, Validation Loss: 0.1759\n",
      "Epoch 350/2000, Train Loss: 0.1434, Validation Loss: 0.1685\n",
      "Epoch 360/2000, Train Loss: 0.1605, Validation Loss: 0.1417\n",
      "Epoch 370/2000, Train Loss: 0.1311, Validation Loss: 0.1539\n",
      "Epoch 380/2000, Train Loss: 0.1091, Validation Loss: 0.1775\n",
      "Epoch 390/2000, Train Loss: 0.1042, Validation Loss: 0.1762\n",
      "Epoch 400/2000, Train Loss: 0.1700, Validation Loss: 0.1638\n",
      "Epoch 410/2000, Train Loss: 0.1321, Validation Loss: 0.1548\n",
      "Epoch 420/2000, Train Loss: 0.1412, Validation Loss: 0.1352\n",
      "Epoch 430/2000, Train Loss: 0.1400, Validation Loss: 0.1649\n",
      "Epoch 440/2000, Train Loss: 0.2006, Validation Loss: 0.1437\n",
      "Epoch 450/2000, Train Loss: 0.1366, Validation Loss: 0.1500\n",
      "Epoch 460/2000, Train Loss: 0.1179, Validation Loss: 0.1718\n",
      "Epoch 470/2000, Train Loss: 0.0843, Validation Loss: 0.1527\n",
      "Epoch 480/2000, Train Loss: 0.1003, Validation Loss: 0.1639\n",
      "Epoch 490/2000, Train Loss: 0.1232, Validation Loss: 0.1517\n",
      "Epoch 500/2000, Train Loss: 0.1175, Validation Loss: 0.1601\n",
      "Epoch 510/2000, Train Loss: 0.1291, Validation Loss: 0.1334\n",
      "Epoch 520/2000, Train Loss: 0.0890, Validation Loss: 0.1686\n",
      "Epoch 530/2000, Train Loss: 0.1171, Validation Loss: 0.1307\n",
      "Epoch 540/2000, Train Loss: 0.1111, Validation Loss: 0.1740\n",
      "Epoch 550/2000, Train Loss: 0.1445, Validation Loss: 0.1527\n",
      "Epoch 560/2000, Train Loss: 0.1134, Validation Loss: 0.1515\n",
      "Epoch 570/2000, Train Loss: 0.1391, Validation Loss: 0.1262\n",
      "Epoch 580/2000, Train Loss: 0.1060, Validation Loss: 0.1454\n",
      "Epoch 590/2000, Train Loss: 0.1189, Validation Loss: 0.1415\n",
      "Epoch 600/2000, Train Loss: 0.1196, Validation Loss: 0.1254\n",
      "Epoch 610/2000, Train Loss: 0.0950, Validation Loss: 0.1375\n",
      "Epoch 620/2000, Train Loss: 0.1425, Validation Loss: 0.1639\n",
      "Epoch 630/2000, Train Loss: 0.1298, Validation Loss: 0.1758\n",
      "Epoch 640/2000, Train Loss: 0.0939, Validation Loss: 0.1744\n",
      "Epoch 650/2000, Train Loss: 0.1043, Validation Loss: 0.1705\n",
      "Epoch 660/2000, Train Loss: 0.0927, Validation Loss: 0.1595\n",
      "Epoch 670/2000, Train Loss: 0.0976, Validation Loss: 0.1696\n",
      "Epoch 680/2000, Train Loss: 0.0877, Validation Loss: 0.1964\n",
      "Epoch 690/2000, Train Loss: 0.0854, Validation Loss: 0.1463\n",
      "Epoch 700/2000, Train Loss: 0.1113, Validation Loss: 0.1445\n",
      "Epoch 710/2000, Train Loss: 0.1007, Validation Loss: 0.1444\n",
      "Epoch 720/2000, Train Loss: 0.1256, Validation Loss: 0.1641\n",
      "Epoch 730/2000, Train Loss: 0.1487, Validation Loss: 0.1359\n",
      "Epoch 740/2000, Train Loss: 0.1275, Validation Loss: 0.1638\n",
      "Epoch 750/2000, Train Loss: 0.1115, Validation Loss: 0.1363\n",
      "Epoch 760/2000, Train Loss: 0.0862, Validation Loss: 0.1816\n",
      "Epoch 770/2000, Train Loss: 0.1435, Validation Loss: 0.1536\n",
      "Epoch 780/2000, Train Loss: 0.0731, Validation Loss: 0.1590\n",
      "Epoch 790/2000, Train Loss: 0.0791, Validation Loss: 0.1313\n",
      "Epoch 800/2000, Train Loss: 0.1105, Validation Loss: 0.1425\n",
      "Epoch 810/2000, Train Loss: 0.1253, Validation Loss: 0.1481\n",
      "Epoch 820/2000, Train Loss: 0.1319, Validation Loss: 0.1393\n",
      "Epoch 830/2000, Train Loss: 0.0784, Validation Loss: 0.1444\n",
      "Epoch 840/2000, Train Loss: 0.0974, Validation Loss: 0.1500\n",
      "Epoch 850/2000, Train Loss: 0.1002, Validation Loss: 0.1564\n",
      "Epoch 860/2000, Train Loss: 0.1469, Validation Loss: 0.1575\n",
      "Epoch 870/2000, Train Loss: 0.0763, Validation Loss: 0.1417\n",
      "Epoch 880/2000, Train Loss: 0.0713, Validation Loss: 0.1527\n",
      "Epoch 890/2000, Train Loss: 0.1265, Validation Loss: 0.1954\n",
      "Epoch 900/2000, Train Loss: 0.1082, Validation Loss: 0.1684\n",
      "Epoch 910/2000, Train Loss: 0.1172, Validation Loss: 0.1635\n",
      "Epoch 920/2000, Train Loss: 0.0602, Validation Loss: 0.1539\n",
      "Epoch 930/2000, Train Loss: 0.0757, Validation Loss: 0.1827\n",
      "Epoch 940/2000, Train Loss: 0.0920, Validation Loss: 0.1802\n",
      "Epoch 950/2000, Train Loss: 0.1441, Validation Loss: 0.1326\n",
      "Epoch 960/2000, Train Loss: 0.0828, Validation Loss: 0.1324\n",
      "Epoch 970/2000, Train Loss: 0.0898, Validation Loss: 0.1699\n",
      "Epoch 980/2000, Train Loss: 0.0973, Validation Loss: 0.1525\n",
      "Epoch 990/2000, Train Loss: 0.0969, Validation Loss: 0.1361\n",
      "Epoch 1000/2000, Train Loss: 0.0930, Validation Loss: 0.1574\n",
      "Epoch 1010/2000, Train Loss: 0.0823, Validation Loss: 0.1483\n",
      "Epoch 1020/2000, Train Loss: 0.0823, Validation Loss: 0.1743\n",
      "Epoch 1030/2000, Train Loss: 0.0680, Validation Loss: 0.1566\n",
      "Epoch 1040/2000, Train Loss: 0.1138, Validation Loss: 0.2000\n",
      "Epoch 1050/2000, Train Loss: 0.1188, Validation Loss: 0.1541\n",
      "Epoch 1060/2000, Train Loss: 0.1358, Validation Loss: 0.1345\n",
      "Epoch 1070/2000, Train Loss: 0.1057, Validation Loss: 0.1614\n",
      "Epoch 1080/2000, Train Loss: 0.0900, Validation Loss: 0.1424\n",
      "Epoch 1090/2000, Train Loss: 0.0822, Validation Loss: 0.1620\n",
      "Epoch 1100/2000, Train Loss: 0.1237, Validation Loss: 0.1240\n",
      "Epoch 1110/2000, Train Loss: 0.1034, Validation Loss: 0.1552\n",
      "Epoch 1120/2000, Train Loss: 0.0910, Validation Loss: 0.1578\n",
      "Epoch 1130/2000, Train Loss: 0.0989, Validation Loss: 0.1542\n",
      "Epoch 1140/2000, Train Loss: 0.0978, Validation Loss: 0.1522\n",
      "Epoch 1150/2000, Train Loss: 0.0868, Validation Loss: 0.1498\n",
      "Epoch 1160/2000, Train Loss: 0.0846, Validation Loss: 0.1406\n",
      "Epoch 1170/2000, Train Loss: 0.1121, Validation Loss: 0.1555\n",
      "Epoch 1180/2000, Train Loss: 0.1077, Validation Loss: 0.1894\n",
      "Epoch 1190/2000, Train Loss: 0.0733, Validation Loss: 0.1684\n",
      "Epoch 1200/2000, Train Loss: 0.0921, Validation Loss: 0.1519\n",
      "Epoch 1210/2000, Train Loss: 0.0934, Validation Loss: 0.1639\n",
      "Epoch 1220/2000, Train Loss: 0.0952, Validation Loss: 0.1653\n",
      "Epoch 1230/2000, Train Loss: 0.1227, Validation Loss: 0.1687\n",
      "Epoch 1240/2000, Train Loss: 0.0736, Validation Loss: 0.1641\n",
      "Epoch 1250/2000, Train Loss: 0.0929, Validation Loss: 0.1641\n",
      "Epoch 1260/2000, Train Loss: 0.0970, Validation Loss: 0.1443\n",
      "Epoch 1270/2000, Train Loss: 0.0644, Validation Loss: 0.1699\n",
      "Epoch 1280/2000, Train Loss: 0.0620, Validation Loss: 0.1627\n",
      "Epoch 1290/2000, Train Loss: 0.0843, Validation Loss: 0.1701\n",
      "Epoch 1300/2000, Train Loss: 0.1119, Validation Loss: 0.1784\n",
      "Epoch 1310/2000, Train Loss: 0.0708, Validation Loss: 0.1687\n",
      "Epoch 1320/2000, Train Loss: 0.0880, Validation Loss: 0.1512\n",
      "Epoch 1330/2000, Train Loss: 0.0880, Validation Loss: 0.1614\n",
      "Epoch 1340/2000, Train Loss: 0.0843, Validation Loss: 0.1703\n",
      "Epoch 1350/2000, Train Loss: 0.1200, Validation Loss: 0.1578\n",
      "Epoch 1360/2000, Train Loss: 0.0896, Validation Loss: 0.1403\n",
      "Epoch 1370/2000, Train Loss: 0.0804, Validation Loss: 0.1670\n",
      "Epoch 1380/2000, Train Loss: 0.0950, Validation Loss: 0.1465\n",
      "Epoch 1390/2000, Train Loss: 0.0619, Validation Loss: 0.1791\n",
      "Epoch 1400/2000, Train Loss: 0.0831, Validation Loss: 0.1778\n",
      "Epoch 1410/2000, Train Loss: 0.1003, Validation Loss: 0.1678\n",
      "Epoch 1420/2000, Train Loss: 0.0868, Validation Loss: 0.1481\n",
      "Epoch 1430/2000, Train Loss: 0.0864, Validation Loss: 0.1577\n",
      "Epoch 1440/2000, Train Loss: 0.0525, Validation Loss: 0.1403\n",
      "Epoch 1450/2000, Train Loss: 0.0938, Validation Loss: 0.1493\n",
      "Epoch 1460/2000, Train Loss: 0.1096, Validation Loss: 0.1564\n",
      "Epoch 1470/2000, Train Loss: 0.0884, Validation Loss: 0.1575\n",
      "Epoch 1480/2000, Train Loss: 0.0890, Validation Loss: 0.1781\n",
      "Epoch 1490/2000, Train Loss: 0.1046, Validation Loss: 0.1599\n",
      "Epoch 1500/2000, Train Loss: 0.1070, Validation Loss: 0.1941\n",
      "Epoch 1510/2000, Train Loss: 0.0940, Validation Loss: 0.1453\n",
      "Epoch 1520/2000, Train Loss: 0.0874, Validation Loss: 0.1427\n",
      "Epoch 1530/2000, Train Loss: 0.1036, Validation Loss: 0.1727\n",
      "Epoch 1540/2000, Train Loss: 0.0709, Validation Loss: 0.1565\n",
      "Epoch 1550/2000, Train Loss: 0.0581, Validation Loss: 0.1508\n",
      "Epoch 1560/2000, Train Loss: 0.1146, Validation Loss: 0.1606\n",
      "Epoch 1570/2000, Train Loss: 0.1048, Validation Loss: 0.1705\n",
      "Epoch 1580/2000, Train Loss: 0.0777, Validation Loss: 0.1565\n",
      "Epoch 1590/2000, Train Loss: 0.0770, Validation Loss: 0.1533\n",
      "Epoch 1600/2000, Train Loss: 0.0817, Validation Loss: 0.1602\n",
      "Epoch 1610/2000, Train Loss: 0.0918, Validation Loss: 0.1530\n",
      "Epoch 1620/2000, Train Loss: 0.0648, Validation Loss: 0.1817\n",
      "Epoch 1630/2000, Train Loss: 0.0701, Validation Loss: 0.1447\n",
      "Epoch 1640/2000, Train Loss: 0.0852, Validation Loss: 0.1579\n",
      "Epoch 1650/2000, Train Loss: 0.1016, Validation Loss: 0.1587\n",
      "Epoch 1660/2000, Train Loss: 0.0421, Validation Loss: 0.1593\n",
      "Epoch 1670/2000, Train Loss: 0.0772, Validation Loss: 0.1630\n",
      "Epoch 1680/2000, Train Loss: 0.0908, Validation Loss: 0.1677\n",
      "Epoch 1690/2000, Train Loss: 0.0765, Validation Loss: 0.1824\n",
      "Epoch 1700/2000, Train Loss: 0.1067, Validation Loss: 0.1642\n",
      "Epoch 1710/2000, Train Loss: 0.0939, Validation Loss: 0.1522\n",
      "Epoch 1720/2000, Train Loss: 0.0955, Validation Loss: 0.1457\n",
      "Epoch 1730/2000, Train Loss: 0.0957, Validation Loss: 0.1888\n",
      "Epoch 1740/2000, Train Loss: 0.0830, Validation Loss: 0.1700\n",
      "Epoch 1750/2000, Train Loss: 0.1037, Validation Loss: 0.1607\n",
      "Epoch 1760/2000, Train Loss: 0.0664, Validation Loss: 0.1697\n",
      "Epoch 1770/2000, Train Loss: 0.0852, Validation Loss: 0.1615\n",
      "Epoch 1780/2000, Train Loss: 0.0670, Validation Loss: 0.1798\n",
      "Epoch 1790/2000, Train Loss: 0.0635, Validation Loss: 0.1825\n",
      "Epoch 1800/2000, Train Loss: 0.1133, Validation Loss: 0.1851\n",
      "Epoch 1810/2000, Train Loss: 0.0730, Validation Loss: 0.1823\n",
      "Epoch 1820/2000, Train Loss: 0.0811, Validation Loss: 0.1692\n",
      "Epoch 1830/2000, Train Loss: 0.0835, Validation Loss: 0.1658\n",
      "Epoch 1840/2000, Train Loss: 0.0856, Validation Loss: 0.1644\n",
      "Epoch 1850/2000, Train Loss: 0.0928, Validation Loss: 0.1590\n",
      "Epoch 1860/2000, Train Loss: 0.0685, Validation Loss: 0.1675\n",
      "Epoch 1870/2000, Train Loss: 0.0689, Validation Loss: 0.1694\n",
      "Epoch 1880/2000, Train Loss: 0.0800, Validation Loss: 0.1651\n",
      "Epoch 1890/2000, Train Loss: 0.0669, Validation Loss: 0.1484\n",
      "Epoch 1900/2000, Train Loss: 0.0900, Validation Loss: 0.1613\n",
      "Epoch 1910/2000, Train Loss: 0.1118, Validation Loss: 0.1371\n",
      "Epoch 1920/2000, Train Loss: 0.0655, Validation Loss: 0.1436\n",
      "Epoch 1930/2000, Train Loss: 0.0893, Validation Loss: 0.1480\n",
      "Epoch 1940/2000, Train Loss: 0.0669, Validation Loss: 0.1762\n",
      "Epoch 1950/2000, Train Loss: 0.0751, Validation Loss: 0.1473\n",
      "Epoch 1960/2000, Train Loss: 0.0703, Validation Loss: 0.1449\n",
      "Epoch 1970/2000, Train Loss: 0.0925, Validation Loss: 0.1546\n",
      "Epoch 1980/2000, Train Loss: 0.0878, Validation Loss: 0.1462\n",
      "Epoch 1990/2000, Train Loss: 0.1019, Validation Loss: 0.1667\n",
      "Epoch 2000/2000, Train Loss: 0.0700, Validation Loss: 0.1738\n",
      "\n",
      "Final Validation MSE: 0.1738\n",
      "Final Validation R²: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. Prepare the feature matrix X and target vector y\n",
    "tokens = list(plogp_map_atoms.keys())\n",
    "X = np.vstack([plogp_map_atoms[tok][1] for tok in tokens])  # shape: (n_tokens, n_features)\n",
    "y = np.array([plogp_map_atoms[tok][0] for tok in tokens], dtype=float)\n",
    "\n",
    "# 2. Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# 3. Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.float32)\n",
    "\n",
    "# 4. Define a deeper MLP model with more layers and Dropout\n",
    "class DeeperMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeeperMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),  # First hidden layer with 128 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),  # Dropout with 30% probability\n",
    "\n",
    "            nn.Linear(128, 64),  # Second hidden layer with 64 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),  # Dropout again\n",
    "\n",
    "            nn.Linear(64, 32),  # Third hidden layer with 32 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "\n",
    "            nn.Linear(32, 1)  # Output layer for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()  # Squeeze to make output 1D\n",
    "\n",
    "# 5. Training parameters\n",
    "epochs = 2000\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 6. Initialize the model, optimizer, and loss function\n",
    "model = DeeperMLP(input_dim=X_train.shape[1]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)  # L2 regularization (weight decay)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 7. Training loop with validation loss tracking\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle the training data\n",
    "    idx = torch.randperm(X_train.size(0))\n",
    "    X_train, y_train = X_train[idx], y_train[idx]\n",
    "\n",
    "    # Mini-batch training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        x_batch = X_train[i:i+batch_size].to(device)\n",
    "        y_batch = y_train[i:i+batch_size].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Compute training loss for the epoch\n",
    "    train_loss /= (len(X_train) // batch_size)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Evaluate validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_valid = model(X_valid.to(device)).cpu().numpy()\n",
    "        valid_loss = mean_squared_error(y_valid.numpy(), y_pred_valid)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "    # Print losses for this epoch\n",
    "    if (epoch+1) % 10 == 0:  # Print every 10 epochs\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}\")\n",
    "\n",
    "# 8. Final evaluation on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_valid = model(X_valid.to(device)).cpu().numpy()\n",
    "    mse = mean_squared_error(y_valid.numpy(), y_pred_valid)\n",
    "    r2 = r2_score(y_valid.numpy(), y_pred_valid)\n",
    "\n",
    "print(f\"\\nFinal Validation MSE: {mse:.4f}\")\n",
    "print(f\"Final Validation R²: {r2:.4f}\")\n",
    "\n",
    "# 9. Plot the training and validation loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T12:21:52.102228Z",
     "start_time": "2025-04-29T12:21:40.793092200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP with one hot encoder for AA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Pycharm_envs\\retention_prediction\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: MSE = 0.1819,  R² = 0.7747\n",
      "Fold 2: MSE = 0.1309,  R² = 0.8734\n",
      "Fold 3: MSE = 0.0586,  R² = 0.9207\n",
      "Fold 4: MSE = 0.0840,  R² = 0.8900\n",
      "Fold 5: MSE = 0.0484,  R² = 0.9668\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Avg MSE over folds: 0.1007 ± 0.0496\n",
      "Avg R²  over folds: 0.8851 ± 0.0637\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Define the list of amino acids and initialize one-hot encoder\n",
    "amino_acids = ['K', 'C', 'A', 'D', 'E', 'F', 'G', 'H', 'I', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'Y', 'W']\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "amino_acid_array = np.array(amino_acids).reshape(-1, 1)\n",
    "one_hot_encoder = encoder.fit(amino_acid_array)\n",
    "\n",
    "# 2. Define the function to encode amino acid and features\n",
    "def encode_amino_acid_and_features(key, value, one_hot_encoder):\n",
    "    \"\"\"\n",
    "    Encodes the amino acid part using one-hot encoding and keeps the modification data as is.\n",
    "\n",
    "    Parameters:\n",
    "    - key: The amino acid (e.g., 'V')\n",
    "    - value: A tuple (pLogP_value, modification_features) from plogp_map_atoms\n",
    "    - one_hot_encoder: The trained OneHotEncoder for amino acids\n",
    "\n",
    "    Returns:\n",
    "    - Combined feature vector consisting of one-hot encoded amino acid and modification features\n",
    "    \"\"\"\n",
    "    # Extract the amino acid (key)\n",
    "    amino_acid = key  # Amino acid is directly in the key (e.g., 'V')\n",
    "\n",
    "    # Extract the modification features (value[1] is the modification data)\n",
    "    modification_features = np.array(value[1])  # The list of modification features\n",
    "\n",
    "    # One-hot encode the amino acid\n",
    "    amino_acid_one_hot = one_hot_encoder.transform([[amino_acid]])  # Get the one-hot encoded vector\n",
    "\n",
    "    # Combine the one-hot encoded amino acid and the modification features\n",
    "    combined_features = np.concatenate((amino_acid_one_hot.flatten(), modification_features))\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "# 3. Prepare the feature matrix X and target vector y from plogp_map_atoms\n",
    "tokens = list(plogp_map_atoms.keys())  # List of keys (e.g., 'F[Acetyl(N-T)]')\n",
    "X = np.vstack([encode_amino_acid_and_features(tok[0], plogp_map_atoms[tok], one_hot_encoder) for tok in tokens])  # shape: (n_tokens, n_features)\n",
    "y = np.array([plogp_map_atoms[tok][0] for tok in tokens], dtype=float)  # Extract pLogP values (float) from the first part of the tuple\n",
    "\n",
    "# 4. Convert data to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 5. Define a simple MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # Regression output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()  # Squeeze to make output 1D\n",
    "\n",
    "# 6. Set up 5-fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mse_scores, r2_scores = [], []\n",
    "\n",
    "# 7. Training parameters\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 8. Cross-validation loop\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = MLP(input_dim=X.shape[1]).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        idx = torch.randperm(X_train.size(0))\n",
    "        X_train, y_train = X_train[idx], y_train[idx]\n",
    "\n",
    "        for i in range(0, X_train.size(0), batch_size):\n",
    "            x_batch = X_train[i:i+batch_size].to(device)\n",
    "            y_batch = y_train[i:i+batch_size].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test.to(device)).cpu().numpy()\n",
    "        y_true_test = y_test.numpy()\n",
    "\n",
    "        mse = mean_squared_error(y_true_test, y_pred_test)\n",
    "        r2 = r2_score(y_true_test, y_pred_test)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(f\"Fold {fold}: MSE = {mse:.4f},  R² = {r2:.4f}\")\n",
    "\n",
    "# 9. Aggregate results across folds\n",
    "print(f\"\\n=== Final Cross-Validation Results ===\")\n",
    "print(f\"Avg MSE over folds: {np.mean(mse_scores):.4f} ± {np.std(mse_scores):.4f}\")\n",
    "print(f\"Avg R²  over folds: {np.mean(r2_scores):.4f} ± {np.std(r2_scores):.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T12:36:58.297029200Z",
     "start_time": "2025-04-29T12:36:47.319032100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Pycharm_envs\\retention_prediction\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/2000, Train Loss: 0.8974, Validation Loss: 0.8689\n",
      "Epoch 20/2000, Train Loss: 0.8687, Validation Loss: 0.7166\n",
      "Epoch 30/2000, Train Loss: 0.6125, Validation Loss: 0.3488\n",
      "Epoch 40/2000, Train Loss: 0.6658, Validation Loss: 0.2107\n",
      "Epoch 50/2000, Train Loss: 0.6338, Validation Loss: 0.1653\n",
      "Epoch 60/2000, Train Loss: 0.4765, Validation Loss: 0.2057\n",
      "Epoch 70/2000, Train Loss: 0.5331, Validation Loss: 0.1605\n",
      "Epoch 80/2000, Train Loss: 0.5126, Validation Loss: 0.1976\n",
      "Epoch 90/2000, Train Loss: 0.3654, Validation Loss: 0.1512\n",
      "Epoch 100/2000, Train Loss: 0.4205, Validation Loss: 0.1564\n",
      "Epoch 110/2000, Train Loss: 0.3782, Validation Loss: 0.2390\n",
      "Epoch 120/2000, Train Loss: 0.4380, Validation Loss: 0.1573\n",
      "Epoch 130/2000, Train Loss: 0.3937, Validation Loss: 0.1501\n",
      "Epoch 140/2000, Train Loss: 0.4357, Validation Loss: 0.1448\n",
      "Epoch 150/2000, Train Loss: 0.3541, Validation Loss: 0.1431\n",
      "Epoch 160/2000, Train Loss: 0.3388, Validation Loss: 0.1220\n",
      "Epoch 170/2000, Train Loss: 0.3264, Validation Loss: 0.1301\n",
      "Epoch 180/2000, Train Loss: 0.3653, Validation Loss: 0.1191\n",
      "Epoch 190/2000, Train Loss: 0.3349, Validation Loss: 0.1134\n",
      "Epoch 200/2000, Train Loss: 0.3785, Validation Loss: 0.1294\n",
      "Epoch 210/2000, Train Loss: 0.3394, Validation Loss: 0.1869\n",
      "Epoch 220/2000, Train Loss: 0.4518, Validation Loss: 0.1907\n",
      "Epoch 230/2000, Train Loss: 0.4337, Validation Loss: 0.1258\n",
      "Epoch 240/2000, Train Loss: 0.2802, Validation Loss: 0.1248\n",
      "Epoch 250/2000, Train Loss: 0.2656, Validation Loss: 0.1175\n",
      "Epoch 260/2000, Train Loss: 0.3086, Validation Loss: 0.1106\n",
      "Epoch 270/2000, Train Loss: 0.2782, Validation Loss: 0.1144\n",
      "Epoch 280/2000, Train Loss: 0.2666, Validation Loss: 0.1160\n",
      "Epoch 290/2000, Train Loss: 0.2730, Validation Loss: 0.1311\n",
      "Epoch 300/2000, Train Loss: 0.2829, Validation Loss: 0.1236\n",
      "Epoch 310/2000, Train Loss: 0.3035, Validation Loss: 0.1287\n",
      "Epoch 320/2000, Train Loss: 0.2455, Validation Loss: 0.1278\n",
      "Epoch 330/2000, Train Loss: 0.3455, Validation Loss: 0.1320\n",
      "Epoch 340/2000, Train Loss: 0.3953, Validation Loss: 0.1242\n",
      "Epoch 350/2000, Train Loss: 0.2413, Validation Loss: 0.1233\n",
      "Epoch 360/2000, Train Loss: 0.3676, Validation Loss: 0.1239\n",
      "Epoch 370/2000, Train Loss: 0.2509, Validation Loss: 0.1045\n",
      "Epoch 380/2000, Train Loss: 0.2815, Validation Loss: 0.1165\n",
      "Epoch 390/2000, Train Loss: 0.3022, Validation Loss: 0.1385\n",
      "Epoch 400/2000, Train Loss: 0.2437, Validation Loss: 0.1555\n",
      "Epoch 410/2000, Train Loss: 0.2583, Validation Loss: 0.1273\n",
      "Epoch 420/2000, Train Loss: 0.2656, Validation Loss: 0.1356\n",
      "Epoch 430/2000, Train Loss: 0.2726, Validation Loss: 0.1156\n",
      "Epoch 440/2000, Train Loss: 0.3397, Validation Loss: 0.1123\n",
      "Epoch 450/2000, Train Loss: 0.2624, Validation Loss: 0.1208\n",
      "Epoch 460/2000, Train Loss: 0.2427, Validation Loss: 0.1173\n",
      "Epoch 470/2000, Train Loss: 0.3448, Validation Loss: 0.1415\n",
      "Epoch 480/2000, Train Loss: 0.3515, Validation Loss: 0.1094\n",
      "Epoch 490/2000, Train Loss: 0.3027, Validation Loss: 0.1558\n",
      "Epoch 500/2000, Train Loss: 0.2525, Validation Loss: 0.1011\n",
      "Epoch 510/2000, Train Loss: 0.2656, Validation Loss: 0.1038\n",
      "Epoch 520/2000, Train Loss: 0.2156, Validation Loss: 0.1234\n",
      "Epoch 530/2000, Train Loss: 0.3056, Validation Loss: 0.1074\n",
      "Epoch 540/2000, Train Loss: 0.2878, Validation Loss: 0.1153\n",
      "Epoch 550/2000, Train Loss: 0.2853, Validation Loss: 0.1043\n",
      "Epoch 560/2000, Train Loss: 0.2357, Validation Loss: 0.1085\n",
      "Epoch 570/2000, Train Loss: 0.2031, Validation Loss: 0.1056\n",
      "Epoch 580/2000, Train Loss: 0.2848, Validation Loss: 0.1018\n",
      "Epoch 590/2000, Train Loss: 0.2998, Validation Loss: 0.0992\n",
      "Epoch 600/2000, Train Loss: 0.3260, Validation Loss: 0.1558\n",
      "Epoch 610/2000, Train Loss: 0.2936, Validation Loss: 0.1028\n",
      "Epoch 620/2000, Train Loss: 0.2215, Validation Loss: 0.1114\n",
      "Epoch 630/2000, Train Loss: 0.2837, Validation Loss: 0.1067\n",
      "Epoch 640/2000, Train Loss: 0.2749, Validation Loss: 0.1188\n",
      "Epoch 650/2000, Train Loss: 0.2487, Validation Loss: 0.1147\n",
      "Epoch 660/2000, Train Loss: 0.2874, Validation Loss: 0.1117\n",
      "Epoch 670/2000, Train Loss: 0.2605, Validation Loss: 0.1076\n",
      "Epoch 680/2000, Train Loss: 0.1876, Validation Loss: 0.1000\n",
      "Epoch 690/2000, Train Loss: 0.2065, Validation Loss: 0.1135\n",
      "Epoch 700/2000, Train Loss: 0.2614, Validation Loss: 0.1301\n",
      "Epoch 710/2000, Train Loss: 0.3980, Validation Loss: 0.1272\n",
      "Epoch 720/2000, Train Loss: 0.3755, Validation Loss: 0.1306\n",
      "Epoch 730/2000, Train Loss: 0.2259, Validation Loss: 0.1154\n",
      "Epoch 740/2000, Train Loss: 0.2467, Validation Loss: 0.1247\n",
      "Epoch 750/2000, Train Loss: 0.2441, Validation Loss: 0.1127\n",
      "Epoch 760/2000, Train Loss: 0.2946, Validation Loss: 0.1213\n",
      "Epoch 770/2000, Train Loss: 0.2849, Validation Loss: 0.0928\n",
      "Epoch 780/2000, Train Loss: 0.2824, Validation Loss: 0.1173\n",
      "Epoch 790/2000, Train Loss: 0.2343, Validation Loss: 0.1151\n",
      "Epoch 800/2000, Train Loss: 0.1944, Validation Loss: 0.1088\n",
      "Epoch 810/2000, Train Loss: 0.2775, Validation Loss: 0.1127\n",
      "Epoch 820/2000, Train Loss: 0.2656, Validation Loss: 0.1118\n",
      "Epoch 830/2000, Train Loss: 0.2659, Validation Loss: 0.1110\n",
      "Epoch 840/2000, Train Loss: 0.2898, Validation Loss: 0.1222\n",
      "Epoch 850/2000, Train Loss: 0.2786, Validation Loss: 0.1193\n",
      "Epoch 860/2000, Train Loss: 0.2320, Validation Loss: 0.1104\n",
      "Epoch 870/2000, Train Loss: 0.2264, Validation Loss: 0.1149\n",
      "Epoch 880/2000, Train Loss: 0.2595, Validation Loss: 0.1172\n",
      "Epoch 890/2000, Train Loss: 0.2904, Validation Loss: 0.1275\n",
      "Epoch 900/2000, Train Loss: 0.2450, Validation Loss: 0.1159\n",
      "Epoch 910/2000, Train Loss: 0.2524, Validation Loss: 0.1140\n",
      "Epoch 920/2000, Train Loss: 0.2274, Validation Loss: 0.0986\n",
      "Epoch 930/2000, Train Loss: 0.3031, Validation Loss: 0.1243\n",
      "Epoch 940/2000, Train Loss: 0.2628, Validation Loss: 0.1156\n",
      "Epoch 950/2000, Train Loss: 0.2157, Validation Loss: 0.1191\n",
      "Epoch 960/2000, Train Loss: 0.2358, Validation Loss: 0.1110\n",
      "Epoch 970/2000, Train Loss: 0.2724, Validation Loss: 0.0954\n",
      "Epoch 980/2000, Train Loss: 0.3490, Validation Loss: 0.1006\n",
      "Epoch 990/2000, Train Loss: 0.2578, Validation Loss: 0.1023\n",
      "Epoch 1000/2000, Train Loss: 0.2453, Validation Loss: 0.1182\n",
      "Epoch 1010/2000, Train Loss: 0.2553, Validation Loss: 0.1542\n",
      "Epoch 1020/2000, Train Loss: 0.2144, Validation Loss: 0.1076\n",
      "Epoch 1030/2000, Train Loss: 0.2139, Validation Loss: 0.1091\n",
      "Epoch 1040/2000, Train Loss: 0.2500, Validation Loss: 0.1304\n",
      "Epoch 1050/2000, Train Loss: 0.2819, Validation Loss: 0.1094\n",
      "Epoch 1060/2000, Train Loss: 0.2557, Validation Loss: 0.0984\n",
      "Epoch 1070/2000, Train Loss: 0.2101, Validation Loss: 0.0961\n",
      "Epoch 1080/2000, Train Loss: 0.3049, Validation Loss: 0.1021\n",
      "Epoch 1090/2000, Train Loss: 0.2449, Validation Loss: 0.1020\n",
      "Epoch 1100/2000, Train Loss: 0.2610, Validation Loss: 0.1144\n",
      "Epoch 1110/2000, Train Loss: 0.2303, Validation Loss: 0.1100\n",
      "Epoch 1120/2000, Train Loss: 0.2854, Validation Loss: 0.1004\n",
      "Epoch 1130/2000, Train Loss: 0.3103, Validation Loss: 0.1168\n",
      "Epoch 1140/2000, Train Loss: 0.2525, Validation Loss: 0.1149\n",
      "Epoch 1150/2000, Train Loss: 0.2156, Validation Loss: 0.0963\n",
      "Epoch 1160/2000, Train Loss: 0.2608, Validation Loss: 0.1406\n",
      "Epoch 1170/2000, Train Loss: 0.2107, Validation Loss: 0.1025\n",
      "Epoch 1180/2000, Train Loss: 0.2327, Validation Loss: 0.1108\n",
      "Epoch 1190/2000, Train Loss: 0.2959, Validation Loss: 0.1146\n",
      "Epoch 1200/2000, Train Loss: 0.2241, Validation Loss: 0.1026\n",
      "Epoch 1210/2000, Train Loss: 0.2410, Validation Loss: 0.0833\n",
      "Epoch 1220/2000, Train Loss: 0.2867, Validation Loss: 0.1033\n",
      "Epoch 1230/2000, Train Loss: 0.2312, Validation Loss: 0.1071\n",
      "Epoch 1240/2000, Train Loss: 0.2115, Validation Loss: 0.1152\n",
      "Epoch 1250/2000, Train Loss: 0.3441, Validation Loss: 0.1000\n",
      "Epoch 1260/2000, Train Loss: 0.2566, Validation Loss: 0.1120\n",
      "Epoch 1270/2000, Train Loss: 0.2229, Validation Loss: 0.0965\n",
      "Epoch 1280/2000, Train Loss: 0.3041, Validation Loss: 0.1075\n",
      "Epoch 1290/2000, Train Loss: 0.2261, Validation Loss: 0.1152\n",
      "Epoch 1300/2000, Train Loss: 0.2799, Validation Loss: 0.1004\n",
      "Epoch 1310/2000, Train Loss: 0.2451, Validation Loss: 0.0932\n",
      "Epoch 1320/2000, Train Loss: 0.2671, Validation Loss: 0.0944\n",
      "Epoch 1330/2000, Train Loss: 0.2957, Validation Loss: 0.1088\n",
      "Epoch 1340/2000, Train Loss: 0.2936, Validation Loss: 0.1404\n",
      "Epoch 1350/2000, Train Loss: 0.3158, Validation Loss: 0.1089\n",
      "Epoch 1360/2000, Train Loss: 0.2969, Validation Loss: 0.1020\n",
      "Epoch 1370/2000, Train Loss: 0.2830, Validation Loss: 0.0963\n",
      "Epoch 1380/2000, Train Loss: 0.1886, Validation Loss: 0.0874\n",
      "Epoch 1390/2000, Train Loss: 0.2160, Validation Loss: 0.0817\n",
      "Epoch 1400/2000, Train Loss: 0.2271, Validation Loss: 0.0901\n",
      "Epoch 1410/2000, Train Loss: 0.2286, Validation Loss: 0.0971\n",
      "Epoch 1420/2000, Train Loss: 0.2184, Validation Loss: 0.1020\n",
      "Epoch 1430/2000, Train Loss: 0.2549, Validation Loss: 0.0984\n",
      "Epoch 1440/2000, Train Loss: 0.2269, Validation Loss: 0.1073\n",
      "Epoch 1450/2000, Train Loss: 0.2834, Validation Loss: 0.1033\n",
      "Epoch 1460/2000, Train Loss: 0.2598, Validation Loss: 0.1255\n",
      "Epoch 1470/2000, Train Loss: 0.2925, Validation Loss: 0.1180\n",
      "Epoch 1480/2000, Train Loss: 0.1899, Validation Loss: 0.1091\n",
      "Epoch 1490/2000, Train Loss: 0.2993, Validation Loss: 0.1194\n",
      "Epoch 1500/2000, Train Loss: 0.2352, Validation Loss: 0.0942\n",
      "Epoch 1510/2000, Train Loss: 0.2708, Validation Loss: 0.0962\n",
      "Epoch 1520/2000, Train Loss: 0.2642, Validation Loss: 0.0865\n",
      "Epoch 1530/2000, Train Loss: 0.2239, Validation Loss: 0.1126\n",
      "Epoch 1540/2000, Train Loss: 0.2443, Validation Loss: 0.1427\n",
      "Epoch 1550/2000, Train Loss: 0.2590, Validation Loss: 0.1123\n",
      "Epoch 1560/2000, Train Loss: 0.2578, Validation Loss: 0.1172\n",
      "Epoch 1570/2000, Train Loss: 0.2452, Validation Loss: 0.1173\n",
      "Epoch 1580/2000, Train Loss: 0.2938, Validation Loss: 0.1507\n",
      "Epoch 1590/2000, Train Loss: 0.2175, Validation Loss: 0.1116\n",
      "Epoch 1600/2000, Train Loss: 0.2584, Validation Loss: 0.1034\n",
      "Epoch 1610/2000, Train Loss: 0.2255, Validation Loss: 0.1038\n",
      "Epoch 1620/2000, Train Loss: 0.2828, Validation Loss: 0.1728\n",
      "Epoch 1630/2000, Train Loss: 0.3183, Validation Loss: 0.0983\n",
      "Epoch 1640/2000, Train Loss: 0.2180, Validation Loss: 0.1071\n",
      "Epoch 1650/2000, Train Loss: 0.2871, Validation Loss: 0.0925\n",
      "Epoch 1660/2000, Train Loss: 0.2409, Validation Loss: 0.1190\n",
      "Epoch 1670/2000, Train Loss: 0.3147, Validation Loss: 0.1340\n",
      "Epoch 1680/2000, Train Loss: 0.2547, Validation Loss: 0.1194\n",
      "Epoch 1690/2000, Train Loss: 0.2760, Validation Loss: 0.1086\n",
      "Epoch 1700/2000, Train Loss: 0.2698, Validation Loss: 0.1121\n",
      "Epoch 1710/2000, Train Loss: 0.2297, Validation Loss: 0.1286\n",
      "Epoch 1720/2000, Train Loss: 0.3000, Validation Loss: 0.1184\n",
      "Epoch 1730/2000, Train Loss: 0.2499, Validation Loss: 0.1531\n",
      "Epoch 1740/2000, Train Loss: 0.2698, Validation Loss: 0.1019\n",
      "Epoch 1750/2000, Train Loss: 0.2290, Validation Loss: 0.1353\n",
      "Epoch 1760/2000, Train Loss: 0.2230, Validation Loss: 0.0895\n",
      "Epoch 1770/2000, Train Loss: 0.2190, Validation Loss: 0.1022\n",
      "Epoch 1780/2000, Train Loss: 0.3147, Validation Loss: 0.1054\n",
      "Epoch 1790/2000, Train Loss: 0.1991, Validation Loss: 0.1112\n",
      "Epoch 1800/2000, Train Loss: 0.2582, Validation Loss: 0.1032\n",
      "Epoch 1810/2000, Train Loss: 0.2943, Validation Loss: 0.1027\n",
      "Epoch 1820/2000, Train Loss: 0.3388, Validation Loss: 0.1215\n",
      "Epoch 1830/2000, Train Loss: 0.2279, Validation Loss: 0.1189\n",
      "Epoch 1840/2000, Train Loss: 0.2283, Validation Loss: 0.1151\n",
      "Epoch 1850/2000, Train Loss: 0.2346, Validation Loss: 0.1264\n",
      "Epoch 1860/2000, Train Loss: 0.2143, Validation Loss: 0.0873\n",
      "Epoch 1870/2000, Train Loss: 0.2450, Validation Loss: 0.1069\n",
      "Epoch 1880/2000, Train Loss: 0.2392, Validation Loss: 0.1024\n",
      "Epoch 1890/2000, Train Loss: 0.2520, Validation Loss: 0.1079\n",
      "Epoch 1900/2000, Train Loss: 0.2266, Validation Loss: 0.0869\n",
      "Epoch 1910/2000, Train Loss: 0.2773, Validation Loss: 0.0817\n",
      "Epoch 1920/2000, Train Loss: 0.3135, Validation Loss: 0.0955\n",
      "Epoch 1930/2000, Train Loss: 0.2501, Validation Loss: 0.1250\n",
      "Epoch 1940/2000, Train Loss: 0.2537, Validation Loss: 0.0939\n",
      "Epoch 1950/2000, Train Loss: 0.2431, Validation Loss: 0.0838\n",
      "Epoch 1960/2000, Train Loss: 0.2306, Validation Loss: 0.1177\n",
      "Epoch 1970/2000, Train Loss: 0.2192, Validation Loss: 0.1122\n",
      "Epoch 1980/2000, Train Loss: 0.2325, Validation Loss: 0.1389\n",
      "Epoch 1990/2000, Train Loss: 0.2290, Validation Loss: 0.0662\n",
      "Epoch 2000/2000, Train Loss: 0.2312, Validation Loss: 0.0872\n",
      "\n",
      "Final Validation MSE: 0.0872\n",
      "Final Validation R²: 0.8849\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Define the list of amino acids and initialize one-hot encoder\n",
    "amino_acids = list(amino_acids_order.keys())\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "amino_acid_array = np.array(amino_acids).reshape(-1, 1)\n",
    "one_hot_encoder = encoder.fit(amino_acid_array)\n",
    "\n",
    "# 2. Define the function to encode amino acid and features\n",
    "def encode_amino_acid_and_features(key, value, one_hot_encoder):\n",
    "    \"\"\"\n",
    "    Encodes the amino acid part using one-hot encoding and keeps the modification data as is.\n",
    "\n",
    "    Parameters:\n",
    "    - key: The amino acid (e.g., 'V')\n",
    "    - value: A tuple (pLogP_value, modification_features) from plogp_map_atoms\n",
    "    - one_hot_encoder: The trained OneHotEncoder for amino acids\n",
    "\n",
    "    Returns:\n",
    "    - Combined feature vector consisting of one-hot encoded amino acid and modification features\n",
    "    \"\"\"\n",
    "    # Extract the amino acid (key)\n",
    "    amino_acid = key  # Amino acid is directly in the key (e.g., 'V')\n",
    "\n",
    "    # Extract the modification features (value[1] is the modification data)\n",
    "    modification_features = np.array(value[1])  # The list of modification features\n",
    "\n",
    "    # One-hot encode the amino acid\n",
    "    amino_acid_one_hot = one_hot_encoder.transform([[amino_acid]])  # Get the one-hot encoded vector\n",
    "\n",
    "    # Combine the one-hot encoded amino acid and the modification features\n",
    "    combined_features = np.concatenate((amino_acid_one_hot.flatten(), modification_features))\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "# 3. Prepare the feature matrix X and target vector y from plogp_map_atoms\n",
    "tokens = list(plogp_map_atoms.keys())  # List of keys (e.g., 'F[Acetyl(N-T)]')\n",
    "X = np.vstack([encode_amino_acid_and_features(tok[0], plogp_map_atoms[tok], one_hot_encoder) for tok in tokens])  # shape: (n_tokens, n_features)\n",
    "y = np.array([plogp_map_atoms[tok][0] for tok in tokens], dtype=float)  # Extract pLogP values (float) from the first part of the tuple\n",
    "\n",
    "# 4. Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 5. Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.float32)\n",
    "\n",
    "# 6. Define a deeper MLP model with more layers and Dropout\n",
    "class DeeperMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeeperMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),  # First hidden layer with 128 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),  # Dropout with 30% probability\n",
    "\n",
    "            nn.Linear(128, 64),  # Second hidden layer with 64 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),  # Dropout again\n",
    "\n",
    "            nn.Linear(64, 32),  # Third hidden layer with 32 neurons\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "\n",
    "            nn.Linear(32, 1)  # Output layer for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()  # Squeeze to make output 1D\n",
    "\n",
    "# 7. Training parameters\n",
    "epochs = 2000\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 8. Initialize the model, optimizer, and loss function\n",
    "model = DeeperMLP(input_dim=X_train.shape[1]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # L2 regularization (weight decay)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# 9. Training loop with validation loss tracking\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle the training data\n",
    "    idx = torch.randperm(X_train.size(0))\n",
    "    X_train, y_train = X_train[idx], y_train[idx]\n",
    "\n",
    "    # Mini-batch training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        x_batch = X_train[i:i+batch_size].to(device)\n",
    "        y_batch = y_train[i:i+batch_size].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Compute training loss for the epoch\n",
    "    train_loss /= (len(X_train) // batch_size)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Evaluate validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_valid = model(X_valid.to(device)).cpu().numpy()\n",
    "        valid_loss = mean_squared_error(y_valid.numpy(), y_pred_valid)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "    # Print losses for this epoch\n",
    "    if (epoch+1) % 10 == 0:  # Print every 10 epochs\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}\")\n",
    "\n",
    "# 10. Final evaluation on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_valid = model(X_valid.to(device)).cpu().numpy()\n",
    "    mse = mean_squared_error(y_valid.numpy(), y_pred_valid)\n",
    "    r2 = r2_score(y_valid.numpy(), y_pred_valid)\n",
    "\n",
    "print(f\"\\nFinal Validation MSE: {mse:.4f}\")\n",
    "print(f\"Final Validation R²: {r2:.4f}\")\n",
    "\n",
    "# 11. Plot the training and validation loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T12:48:15.195728800Z",
     "start_time": "2025-04-29T12:48:04.535527400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.1918\n",
      "Validation R²: 0.8067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Pycharm_envs\\retention_prediction\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Define the list of amino acids and initialize one-hot encoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "amino_acid_array = np.array(amino_acids).reshape(-1, 1)\n",
    "one_hot_encoder = encoder.fit(amino_acid_array)\n",
    "\n",
    "# 2. Define the function to encode amino acid and features\n",
    "def encode_amino_acid_and_features(key, value, one_hot_encoder):\n",
    "    \"\"\"\n",
    "    Encodes the amino acid part using one-hot encoding and keeps the modification data as is.\n",
    "\n",
    "    Parameters:\n",
    "    - key: The amino acid (e.g., 'V')\n",
    "    - value: A tuple (pLogP_value, modification_features) from plogp_map_atoms\n",
    "    - one_hot_encoder: The trained OneHotEncoder for amino acids\n",
    "\n",
    "    Returns:\n",
    "    - Combined feature vector consisting of one-hot encoded amino acid and modification features\n",
    "    \"\"\"\n",
    "    # Extract the amino acid (key)\n",
    "    amino_acid = key  # Amino acid is directly in the key (e.g., 'V')\n",
    "\n",
    "    # Extract the modification features (value[1] is the modification data)\n",
    "    modification_features = np.array(value[1])  # The list of modification features\n",
    "\n",
    "    # One-hot encode the amino acid\n",
    "    amino_acid_one_hot = one_hot_encoder.transform([[amino_acid]])  # Get the one-hot encoded vector\n",
    "\n",
    "    # Combine the one-hot encoded amino acid and the modification features\n",
    "    combined_features = np.concatenate((amino_acid_one_hot.flatten(), modification_features))\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "# 3. Prepare the feature matrix X and target vector y from plogp_map_atoms\n",
    "tokens = list(plogp_map_atoms.keys())  # List of keys (e.g., 'F[Acetyl(N-T)]')\n",
    "X = np.vstack([encode_amino_acid_and_features(tok[0], plogp_map_atoms[tok], one_hot_encoder) for tok in tokens])  # shape: (n_tokens, n_features)\n",
    "y = np.array([plogp_map_atoms[tok][0] for tok in tokens], dtype=float)  # Extract pLogP values (float) from the first part of the tuple\n",
    "\n",
    "# 4. Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 5. Initialize and train the Random Forest Regressor\n",
    "svr_model = SVR(kernel='rbf', C=200, gamma=0.01, epsilon=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_valid = svr_model.predict(X_valid)\n",
    "\n",
    "# 7. Calculate MSE and R²\n",
    "mse = mean_squared_error(y_valid, y_pred_valid)\n",
    "r2 = r2_score(y_valid, y_pred_valid)\n",
    "\n",
    "# 8. Print results\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "print(f\"Validation R²: {r2:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T12:57:51.878463700Z",
     "start_time": "2025-04-29T12:57:51.848564200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.1590\n",
      "Validation R²: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Pycharm_envs\\retention_prediction\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Define the list of amino acids and initialize one-hot encoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "amino_acid_array = np.array(amino_acids).reshape(-1, 1)\n",
    "one_hot_encoder = encoder.fit(amino_acid_array)\n",
    "\n",
    "# 2. Define the function to encode amino acid and features\n",
    "def encode_amino_acid_and_features(key, value, one_hot_encoder):\n",
    "    \"\"\"\n",
    "    Encodes the amino acid part using one-hot encoding and keeps the modification data as is.\n",
    "\n",
    "    Parameters:\n",
    "    - key: The amino acid (e.g., 'V')\n",
    "    - value: A tuple (pLogP_value, modification_features) from plogp_map_atoms\n",
    "    - one_hot_encoder: The trained OneHotEncoder for amino acids\n",
    "\n",
    "    Returns:\n",
    "    - Combined feature vector consisting of one-hot encoded amino acid and modification features\n",
    "    \"\"\"\n",
    "    # Extract the amino acid (key)\n",
    "    amino_acid = key  # Amino acid is directly in the key (e.g., 'V')\n",
    "\n",
    "    # Extract the modification features (value[1] is the modification data)\n",
    "    modification_features = np.array(value[1])  # The list of modification features\n",
    "\n",
    "    # One-hot encode the amino acid\n",
    "    amino_acid_one_hot = one_hot_encoder.transform([[amino_acid]])  # Get the one-hot encoded vector\n",
    "\n",
    "    # Combine the one-hot encoded amino acid and the modification features\n",
    "    combined_features = np.concatenate((amino_acid_one_hot.flatten(), modification_features))\n",
    "\n",
    "    return combined_features\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# 3. Prepare the feature matrix X and target vector y from plogp_map_atoms\n",
    "tokens = list(plogp_map_atoms.keys())  # List of keys (e.g., 'F[Acetyl(N-T)]')\n",
    "X = np.vstack([encode_amino_acid_and_features(tok[0], plogp_map_atoms[tok], one_hot_encoder) for tok in tokens])  # shape: (n_tokens, n_features)\n",
    "y = np.array([plogp_map_atoms[tok][0] for tok in tokens], dtype=float)  # Extract pLogP values (float) from the first part of the tuple\n",
    "\n",
    "# 4. Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_valid = lr_model.predict(X_valid)\n",
    "\n",
    "\n",
    "# 7. Calculate MSE and R²\n",
    "mse = mean_squared_error(y_valid, y_pred_valid)\n",
    "r2 = r2_score(y_valid, y_pred_valid)\n",
    "\n",
    "# 8. Print results\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "print(f\"Validation R²: {r2:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T12:56:19.800448900Z",
     "start_time": "2025-04-29T12:56:19.782506600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "emb = aa_embeddings  # (20, D)\n",
    "coords = PCA(n_components=2).fit_transform(emb)\n",
    "\n",
    "plt.scatter(coords[:,0], coords[:,1])\n",
    "for aa,i in amino_acids_order.items():\n",
    "    plt.text(coords[i,0]+0.02, coords[i,1]+0.02, aa)\n",
    "plt.title(\"PCA of AA embeddings\"); plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T12:34:06.756005700Z",
     "start_time": "2025-04-29T12:34:06.669780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
